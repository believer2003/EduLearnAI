{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a657abc",
   "metadata": {},
   "source": [
    "# Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6bfbf21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.llms import OpenAI\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Pinecone\n",
    "import pinecone\n",
    "from langchain.prompts import PromptTemplate\n",
    "import os\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain.schema import HumanMessage,AIMessage,SystemMessage\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "import random\n",
    "import pdf2image \n",
    "from PIL import Image\n",
    "import google.generativeai as genai\n",
    "from langchain.prompts import PromptTemplate\n",
    "from pdf2image import convert_from_path\n",
    "from langchain_community.vectorstores import Chroma,FAISS\n",
    "import json\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.memory import ConversationBufferMemory,ConversationSummaryMemory\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "import time\n",
    "# from openai import OpenAI\n",
    "from langchain_chroma import Chroma\n",
    "from langchain.chains import ConversationChain\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16eb7bf2",
   "metadata": {},
   "source": [
    "# API KEYS \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "834d8e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "open_ai_key=\"OPEN_AI_API_KEY_HERE\"\n",
    "os.environ[\"OPENAI_API_KEY\"] = open_ai_key\n",
    "genai.configure(api_key='GEMINI_API_KEY_HERE')\n",
    "os.environ['GROQ_API_KEY']='GROQ_API_KEY_HERE'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7bdcb09",
   "metadata": {},
   "source": [
    "# Model Intialization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "005f01b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mac/anaconda3/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.chat_models.openai.ChatOpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "model = genai.GenerativeModel(\"gemini-1.5-flash-latest\")\n",
    "chat_llm = ChatOpenAI(temperature=0.5)\n",
    "chat = ChatGroq(temperature=0.4, model_name=\"Mixtral-8x7b-32768\")\n",
    "Chroma_db = Chroma(embedding_function=OpenAIEmbeddings())\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=800,\n",
    "    chunk_overlap=200,\n",
    "    length_function=len,\n",
    ")\n",
    "chat2=ChatGroq(api_key='GROQ_API_KEY_HERE',temperature=0.6,model='Llama3-70b-8192')\n",
    "chat3=ChatGroq(api_key='GROQ_API_KEY_HERE',model='Llama3-8b-8192',temperature=0.6)\n",
    "models=[chat,chat2,chat3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8271f4",
   "metadata": {},
   "source": [
    "# PDF TO TEXT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "daef3eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdf_to_text(pdf_path):\n",
    "    pages=[]\n",
    "    images= convert_from_path(pdf_path)\n",
    "    for i in range(len(images)):\n",
    "        images[i].save('page.jpg')\n",
    "        img=Image.open('page.jpg')\n",
    "        res=model.generate_content(['''\n",
    "    Act as a image to text converter.if the image contains text then extract text from it and add some value to make\n",
    "    it more meaningful for further processing.Also if image contains diagrams,flowcharts or any thing other than text\n",
    "    then generate text giving a detailed description about that diagram.\n",
    "    All the informational should be meaningful and in technical language.\n",
    "    ''',img])\n",
    "        try:\n",
    "            print(\"page\"+str(i+1)+\"done\")\n",
    "            pages.append(res.text)\n",
    "        except:\n",
    "            pass\n",
    "    return pages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "167d9743",
   "metadata": {},
   "source": [
    "# TEXT TO DOCUMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a8bb534",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "@dataclass\n",
    "class Document:\n",
    "    page_content: str\n",
    "    metadata: dict\n",
    "def text_to_doc(pages):\n",
    "    documents=[]\n",
    "    j=1\n",
    "    for i in pages:\n",
    "        documents.append(Document(page_content=i, metadata={'source':'source', 'page': j}))\n",
    "        j+=1\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb0b606",
   "metadata": {},
   "source": [
    "# Text Splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5532d986",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_text(docs):\n",
    "    texts=text_splitter.split_documents(docs)\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208f0241",
   "metadata": {},
   "source": [
    "# ADD TO DATABASE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f865fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_to_db(docs):\n",
    "    db=Chroma()\n",
    "    faiss_db = Chroma.from_documents(docs,OpenAIEmbeddings())\n",
    "    return faiss_db"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dfb18d5",
   "metadata": {},
   "source": [
    "# MAIN TEXT EXTRACTER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7258f492",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text(pdf_path):\n",
    "    pages=pdf_to_text(pdf_path)\n",
    "    docs=text_to_doc(pages)\n",
    "    faiss_db=None\n",
    "    return faiss_db,docs,pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "70f9b429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page1done\n",
      "page2done\n"
     ]
    }
   ],
   "source": [
    "faiss_db,docs,pages=extract_text('./cell_guide.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ef09c1fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "memory Initialed\n"
     ]
    }
   ],
   "source": [
    "ans=start_quiz2('hard',docs,pages,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "426690e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_json(que,model):\n",
    "    ind=que.index('[')\n",
    "    que=que[ind:]\n",
    "    i=0\n",
    "    que = que.replace('\\n', '')\n",
    "    try:\n",
    "        que=que.replace('\\\\','')\n",
    "    except:\n",
    "         pass\n",
    "    json_list=json.loads(que)\n",
    "    for i in range(len(json_list)):\n",
    "        (json_list[i])['id']=i\n",
    "        (json_list[i])['answered']=0\n",
    "    return json_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "5eff41bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(convert_json(que,'mixtral'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c642984c",
   "metadata": {},
   "source": [
    "# Main Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b0e564a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_quiz(pdf_path,level):\n",
    "    pdf_to_text(pdf_path)\n",
    "    split_text()\n",
    "    add_to_db()\n",
    "    dic={}\n",
    "    if 'flowmessages' not in dic.keys():\n",
    "        prompt=PromptTemplate(template='''\n",
    "    Greetings! For this task, you will act as a quiz bot. \n",
    "    Your goal is to ask a single question based on the provided data and generate \n",
    "    four unique options. Three of these options should be incorrect, while one should \n",
    "    be correct. Additionally, provide an explanation for why the correct option is \n",
    "    indeed correct, using your intelligence to craft a descriptive explanation.\n",
    "\n",
    "    Ensure that the questions are relevant to the given text and also \n",
    "    dont ask any question related to any image technique or any image \n",
    "\n",
    "    Please provide the questions in JSON format, structured as follows:\n",
    "      \"id\":\"unique integer id\"  \n",
    "      \"question\": \"The question you're asking\",\n",
    "      \"option1\": \"Incorrect option 1\",\n",
    "      \"option2\": \"Incorrect option 2\",\n",
    "      \"option3\": \"Incorrect option 3\",\n",
    "      \"option4\": \"Correct option\"\n",
    "      \"correct_option\": \"D\",\n",
    "      \"answered\":integer:0,\n",
    "      \"chosen\":\"\",\n",
    "      \"summary\": \"Explanation for why the correct option is correct\"\n",
    "    Strive to develop questions and options quickly, within 2-3 seconds.\n",
    "    questions asked should be with a difficuly level of {diff_level}\n",
    "    You can also use history content to make more questions but remember questions and \n",
    "    options should be unique every time\n",
    "    ''',input_variables=['diff_level'])\n",
    "\n",
    "        dic['flowmessages']=[SystemMessage(content=prompt.format(diff_level=level))]\n",
    "        for i in range(3):\n",
    "            ind=random.randint(0,len(texts)-1)\n",
    "            ind2=random.randint(0,len(texts[ind])-1)\n",
    "            con=texts[ind][ind2]\n",
    "#             print(con)\n",
    "            dic['flowmessages'].append(HumanMessage(content=con))\n",
    "            ans=chat_llm(dic['flowmessages'])\n",
    "            dic['flowmessages'].append(AIMessage(content=ans.content))\n",
    "            res=json.loads(ans.content)\n",
    "#             print(type(ans.content))\n",
    "            questions.append(res)\n",
    "            print('Q'+str(i+1)+')'+ans.content)\n",
    "            for i in range(100):\n",
    "                print('-',end='')\n",
    "            print()\n",
    "#         time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f37e79c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory=None\n",
    "def start_quiz3(level,docs,pages,memo):\n",
    "    global memory\n",
    "    template='''\n",
    "    Greetings! For this task, you will act as a quiz bot. \n",
    "    Your goal is to ask generate only 9 different question based on the provided data and generate \n",
    "    four unique options. Three of these options should be incorrect, while one should \n",
    "    be correct. Additionally, provide an explanation for why the correct option is \n",
    "    indeed correct, using your intelligence to craft a descriptive explanation.\n",
    "    don,t write anything other than questions\n",
    "    remember:-remove any newline character\n",
    "    Ensure that the questions are relevant to the given text and also \n",
    "    dont ask any question related to any image technique or any image \n",
    "\n",
    "    Please provide the questions in JSON format, structured as follows:\n",
    "      \"id\":\"unique integer id starting from 0,1,2 so-on\"  \n",
    "      \"question\": \"The question you're asking\",\n",
    "      \"option1\": \"Incorrect option 1\",\n",
    "      \"option2\": \"Incorrect option 2\",\n",
    "      \"option3\": \"Incorrect option 3\",\n",
    "      \"option4\": \"Correct option\"\n",
    "      \"correct_option\": \"D\",\n",
    "      \"answered\":\"integer 0 only\",\n",
    "      \"chosen\":\"\",\n",
    "      \"summary\": \"Explanation for why the correct option is correct\"\n",
    "    Strive to develop questions and options quickly, within 2-3 seconds.\n",
    "    difficulty level of the questions should be {human_input}.\n",
    "    You can also use history content to make more questions but remember questions and \n",
    "    options should be unique every time.You are required to develop a Unique question each time \n",
    "    use memory to saw previous questions and develop completely different questions\n",
    "    \n",
    "        {chat_history}\n",
    "Content for forming questions: {context}\n",
    "Chatbot:\"\"\n",
    "'''\n",
    "    prompt = PromptTemplate(input_variables=[\"chat_history\", \"human_input\", \"context\"], template=template)\n",
    "    if (memo==0):\n",
    "        print(\"memory Initialed\")\n",
    "        memory = ConversationBufferMemory(memory_key=\"chat_history\", input_key=\"human_input\")\n",
    "    else:\n",
    "        print(\"using previous memory\")\n",
    "    chain = load_qa_chain(chat, chain_type=\"stuff\", memory=memory, prompt=prompt)\n",
    "#     db,docs,pages=extract_text(docs)\n",
    "    if(len(pages)>5):\n",
    "        no=random.randint(0,len(pages)-5)\n",
    "        x=chain({\"input_documents\":docs[no:no+5], \"human_input\":level}, return_only_outputs=True)\n",
    "    else:\n",
    "        x=chain({\"input_documents\":docs, \"human_input\":level}, return_only_outputs=True)\n",
    "    return x['output_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0551e71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation=None\n",
    "def start_quiz2(level,docs,pages,memo):\n",
    "#     chat_llm= ChatGroq(temperature=0.6, model_name=\"Mixtral-8x7b-32768\")\n",
    "    global conversation\n",
    "    prompt1=PromptTemplate(template='''\n",
    "    SYSTEM:Greetings! For this task, you will act as a quiz bot. \n",
    "    Your goal is to ask generate only 9 different question based on the provided data and generate \n",
    "    four unique options. Three of these options should be incorrect, while one should \n",
    "    be correct. Additionally, provide an explanation for why the correct option is \n",
    "    indeed correct, using your intelligence to craft a descriptive explanation.\n",
    "    don,t write anything other than questions\n",
    "    remember:-remove any newline character\n",
    "    Ensure that the questions are relevant to the given text and also \n",
    "    dont ask any question related to any image technique or any image \n",
    "\n",
    "    Please provide the questions in JSON format, structured as follows:\n",
    "      \"id\":\"unique integer id starting from 0,1,2 so-on\"  \n",
    "      \"question\": \"The question you're asking\",\n",
    "      \"option1\": \"Incorrect option 1\",\n",
    "      \"option2\": \"Incorrect option 2\",\n",
    "      \"option3\": \"Incorrect option 3\",\n",
    "      \"option4\": \"Correct option\"\n",
    "      \"correct_option\": \"D\",\n",
    "      \"answered\":\"integer 0 only\",\n",
    "      \"chosen\":\"\",\n",
    "      \"summary\": \"Explanation for why the correct option is correct\"\n",
    "    Strive to develop questions and options quickly, within 2-3 seconds.\n",
    "    difficulty level of the questions should be {level}.\n",
    "    ''',input_variables=['level'])\n",
    "    PROMPT=PromptTemplate(template=prompt1.format(level=level)+\n",
    "    '''You can also use history content to make more questions but remember questions and \n",
    "    options should be unique every time.You are required to develop a Unique question each time \n",
    "    use memory to saw previous questions and develop completely different questions\n",
    "    Already Generated Questions:{history}\n",
    "    Content for forming new questions: {input}\n",
    "    AI:\"\"\n",
    "    ''',input_variables=[\"history\",'input'])\n",
    "    if(memo==0):\n",
    "        conversation = ConversationChain(\n",
    "        prompt=PROMPT,\n",
    "        llm=chat,\n",
    "        verbose=True,\n",
    "        memory=ConversationBufferMemory(k=2),\n",
    "#         memory=ConversationSummaryMemory(llm=OpenAI(), max_token_limit=2000)\n",
    "        )\n",
    "        print(\"memory Initialized\")\n",
    "    if(len(pages)>5):\n",
    "        no=random.randint(0,len(pages)-5)\n",
    "        questions=conversation.predict(input=pages[no:no+5])\n",
    "    else:\n",
    "        questions=conversation.predict(input=pages)\n",
    "    return questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7471e579",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.randrange(0,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2d052322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page1done\n",
      "page2done\n"
     ]
    }
   ],
   "source": [
    "db,docs,page=extract_text('./cell_guide.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "b140fa8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "    SYSTEM:Greetings! For this task, you will act as a quiz bot. \n",
      "    Your goal is to ask generate only 9 different question based on the provided data and generate \n",
      "    four unique options. Three of these options should be incorrect, while one should \n",
      "    be correct. Additionally, provide an explanation for why the correct option is \n",
      "    indeed correct, using your intelligence to craft a descriptive explanation.\n",
      "    don,t write anything other than questions\n",
      "    remember:-remove any newline character\n",
      "    Ensure that the questions are relevant to the given text and also \n",
      "    dont ask any question related to any image technique or any image \n",
      "\n",
      "    Please provide the questions in JSON format, structured as follows:\n",
      "      \"id\":\"unique integer id starting from 0,1,2 so-on\"  \n",
      "      \"question\": \"The question you're asking\",\n",
      "      \"option1\": \"Incorrect option 1\",\n",
      "      \"option2\": \"Incorrect option 2\",\n",
      "      \"option3\": \"Incorrect option 3\",\n",
      "      \"option4\": \"Correct option\"\n",
      "      \"correct_option\": \"D\",\n",
      "      \"answered\":\"integer 0 only\",\n",
      "      \"chosen\":\"\",\n",
      "      \"summary\": \"Explanation for why the correct option is correct\"\n",
      "    Strive to develop questions and options quickly, within 2-3 seconds.\n",
      "    difficulty level of the questions should be Easy.\n",
      "    You can also use history content to make more questions but remember questions and \n",
      "    options should be unique every time.You are required to develop a Unique question each time \n",
      "    use memory to saw previous questions and develop completely different questions\n",
      "    Already Generated Questions:Human: []\n",
      "AI: [\n",
      "  {\n",
      "    \"id\":0,\n",
      "    \"question\": \"What type of system is the human body, open or closed?\",\n",
      "    \"option1\": \"The human body is a closed system.\",\n",
      "    \"option2\": \"The human body is a mechanical system.\",\n",
      " \n",
      "   \"option3\": \"The human body is a fluid system.\",\n",
      "    \"option4\": \"The human body is an open system.\",\n",
      "    \"correct_option\": \"D\",\n",
      "    \"answered\":\"0\",\n",
      "    \"chosen\":\"\",\n",
      "    \"summary\": \"The human body is an open system because it exchanges matter and energy with its surroundings.\"\n",
      "  },\n",
      " \n",
      "  {\n",
      "    \"id\":1,\n",
      "\n",
      "    \"question\": \"What is the primary function of the human circulatory system?\",\n",
      "\n",
      "    \"option1\": \"To digest food.\",\n",
      "\n",
      "    \"option2\": \"To maintain water balance.\",\n",
      "\n",
      "    \"option3\": \"To produce insulin.\",\n",
      "\n",
      "    \"option4\": \"To transport nutri ents and oxygen to cells and remove waste products.\",\n",
      "\n",
      "    \"correct_empty\": \"D\",\n",
      "\n",
      "    \"answered\":\"0\",\n",
      "\n",
      "    \"chosen\":\"\",\n",
      "\n",
      "    \"summary\": \"The circulatory system transports nutrients and oxygen to cells and removes waste products, a process essential for the body's survival.\"\n",
      "\n",
      "  },\n",
      "\n",
      "  {\n",
      "\n",
      "    \"id\":2,\n",
      "\n",
      "    \"question\": \"What is the largest organ in the human body?\",\n",
      "\n",
      "    \"option1\": \"The brain.\",\n",
      "\n",
      "    \"option2\": \"The heart.\",\n",
      "\n",
      "    \"option3\": \"The lungs.\",\n",
      "\n",
      "    \"option4\": \"The skin.\",\n",
      "\n",
      "    \"correct_option\": \"D\",\n",
      "\n",
      "    \"answered\":\"0\",\n",
      "\n",
      "    \"chosen\":\"\",\n",
      "\n",
      "    \"summary\": \"The skin is the largest organ in the human body, with a surface area of approximately 2 square meters.\"\n",
      "\n",
      "  },\n",
      "\n",
      "  {\n",
      "\n",
      "    \"id\":3,\n",
      "\n",
      "    \"question\": \"What type of cells are responsible for the production of insulin in the human body?\",\n",
      "\n",
      "    \"option1\": \"Muscle cells.\",\n",
      "\n",
      "    \"option2\": \"Liver cells.\",\n",
      "\n",
      "    \"option3\": \"Beta cells.\",\n",
      "\n",
      "    \"option4\": \"Nerve cells.\",\n",
      "\n",
      "    \"correct_option\": \"C\",\n",
      "\n",
      "    \"answered\":\"0\",\n",
      "\n",
      "    \"chosen\":\"\",\n",
      "\n",
      "    \"summary\": \"Beta cells, located in the pancreas, are responsible for the production and release of insulin in the human body.\"\n",
      "\n",
      "  },\n",
      "\n",
      "  {\n",
      "\n",
      "    \"id\":4,\n",
      "\n",
      "    \"question\": \"What is the main hormone responsible for regulating blood sugar levels in the human body?\",\n",
      "\n",
      "    \"option1\": \"Estrogen.\",\n",
      "\n",
      "    \"option2\": \"Testosterone.\",\n",
      "\n",
      "    \"option3\": \"Ghrelin.\",\n",
      "\n",
      "    \"option4\": \"Insulin.\",\n",
      "\n",
      "    \"correct_option\": \"D\",\n",
      "\n",
      "    \"answered\":\"0\",\n",
      "\n",
      "    \"chosen\":\"\",\n",
      "\n",
      "    \"summary\": \"Insulin is the primary hormone responsible for regulating blood sugar levels in the human body.\"\n",
      "\n",
      "  },\n",
      "\n",
      "  {\n",
      "\n",
      "    \"id\":5,\n",
      "\n",
      "    \"question\": \"What is the scientific term for the process of aging in the human body?\",\n",
      "\n",
      "    \"option1\": \"Metabolism.\",\n",
      "\n",
      "    \"option2\": \"Homeostasis.\",\n",
      "\n",
      "    \"option3\": \"Gerontology.\",\n",
      "\n",
      "    \"option4\": \"Senescence.\",\n",
      "\n",
      "    \"correct_option\": \"D\",\n",
      "\n",
      "    \"answ\n",
      "\n",
      "    ered\":\"0\",\n",
      "\n",
      "    \"chosen\":\"\",\n",
      "\n",
      "    \"summary\": \"Senescence is the scientific term for the process of aging in the human body.\"\n",
      "\n",
      "  },\n",
      "\n",
      "  {\n",
      "\n",
      "    \"id\":6,\n",
      "\n",
      "    \"question\": \"What is the average adult human body temperature in degrees Celsius?\",\n",
      "\n",
      "    \"option1\": \"36.1 degrees Celsius.\",\n",
      "\n",
      "    \"option2\": \"37.0 degrees Celsius.\",\n",
      "\n",
      "    \"option3\": \"38.0 degrees Celsius.\",\n",
      "\n",
      "    \"option4\": \"39.0 degrees Celsius.\",\n",
      "\n",
      "    \"correct_option\": \"B\",\n",
      "\n",
      "    \"answered\":\"0\",\n",
      "\n",
      "    \"chosen\":\"\",\n",
      "\n",
      "    \"summary\": \"The average adult human body temperature is approximately 37.0 degrees Celsius.\"\n",
      "\n",
      "  },\n",
      "\n",
      "  {\n",
      "\n",
      "    \"id\":7,\n",
      "\n",
      "    \"question\": \"What is the primary function of the human respir\n",
      "\n",
      "    iratory system?\",\n",
      "\n",
      "    \"option1\": \"To produce insulin.\",\n",
      "\n",
      "    \"option2\": \"To maintain water balance.\",\n",
      "\n",
      "    \"option3\": \"To remove waste products.\",\n",
      "\n",
      "    \"option4\": \"To take in oxygen and expel carbon dioxide.\",\n",
      "\n",
      "    \"correct_option\": \"D\",\n",
      "\n",
      "    \"answered\":\"0\",\n",
      "\n",
      "    \"chosen\":\"\",\n",
      "\n",
      "    \"summary\": \"The primary function of the human respiratory system is to take in oxygen and expel carbon dioxide.\"\n",
      "\n",
      "  },\n",
      "\n",
      "  {\n",
      "\n",
      "    \"id\":8,\n",
      "\n",
      "    \"question\": \"What is the scientific term for the study of the human body?\",\n",
      "\n",
      "    \"option1\": \"Anatomy.\",\n",
      "\n",
      "    \"option2\": \"Physiology.\",\n",
      "\n",
      "    \"option3\": \"Pathology.\",\n",
      "\n",
      "    \"option4\": \"Histology.\",\n",
      "\n",
      "    \"correct_option\": \"A\",\n",
      "\n",
      "    \"answered\":\"0\",\n",
      "\n",
      "    \"chosen\":\"\",\n",
      "\n",
      "    \"summary\": \"Anatomy is the scientific term for the study of the human body.\"\n",
      "\n",
      "  }\n",
      "\n",
      "]\n",
      "    Content for forming new questions: [\"## 2024 Software Engineer Program - Full-Time\\n\\nThis document outlines the details of the 2024 Software Engineer Program at JPMorgan Chase, focusing on the full-time track.  It emphasizes the program's emphasis on building resilient technology solutions that support the firm's global business, encompassing millions of customers, clients, and employees worldwide. \\n\\n**Key Program Features:**\\n\\n- **Global Reach:** The program is integrated into a global financial institution with 16 strategic technology locations worldwide. \\n- **Focus on Innovation:**  The program leverages a $11 billion annual investment in technology to drive innovation in areas like big data, mobile solutions, cybersecurity, machine learning, and cloud development.\\n- **Diverse Skillset Development:** The program nurtures a diverse set of skills, including application, data, and infrastructure architecture, design across systems, developmental toolsets, and collaborative practices.\\n- **Technical Expertise:** The program emphasizes proficiency in multiple general-purpose programming languages like Java, Python, HADDOOP, Robotics, Web Apps, and Mobile Apps, along with  understanding of software skills such as business analysis, development, maintenance, and improvement.\\n\\n**Program Structure and Impact:**\\n\\n- **Two-Year Program:** The program spans two years, commencing with an orientation covering strategies, products, and an overview of the technology community.\\n- **Technical Learning:**  The program provides insights into the firm's overall efficiency and explores how technology enhances clients' experiences.\\n- **Practical Experience:**  Participants will engage in software engineering within consumer, wholesale, or corporate businesses. \\n- **Mentorship and Networking:**  The program provides hands-on experience, one-on-one mentoring, and opportunities to meet with senior business leaders to build professional networks.\\n- **Impactful Contributions:** Participants will make significant contributions by:\\n    - Engaging in the planning, architecture, development, and implementation of applications.\\n    - Writing, modifying, and testing software.\\n    - Participating in next-generation technologies focused on big data, cybersecurity, DevOps, and cloud,  and continuous integration and deployment.\\n    - Helping grow and build technology platforms that will be utilized by almost half of all US households and many of the world's most prominent corporate, institutional and government clients.\\n\\nThis program offers a comprehensive and challenging opportunity for individuals seeking a fulfilling and impactful career in software engineering within a global financial institution.  It emphasizes innovation, technical expertise, and a collaborative environment to equip participants with the skills and experience necessary to thrive in the ever-evolving technological landscape. \\n\", 'The document describes the prize conditions and general rules for a hackathon. It details:\\n\\n**Prize Conditions:**\\n* All prizes are awarded \"AS IS\" and cannot be transferred or assigned.\\n* The cash equivalent of the prize is not permitted. \\n* JPMC reserves the right to substitute a prize with another prize of equal or greater value.\\n* Participants agree to the use of their name, photograph, voice recording, and likeness for publicity purposes by JPMC without additional compensation or permission. \\n\\n**General Information:**\\n* Submission of an entry does not guarantee participation in the hackathon.\\n* JPMC is not responsible for incomplete, lost, or misdirected entries.\\n* JPMC is also not responsible for transmission defaults, computer server failure, or delayed, garbled, or corrupted data transmissions.\\n* Participants are responsible for any communications that do not arrive due to entrant\\'s internet service provider. \\n* Participants who are provisionally accepted for the hackathon will be sent a notice to the e-mail address in their entry form and will be required to confirm receipt of such notice and attendance at the hackathon.\\n* In the event that confirmation is not received by the date requested in the notice, the participant will be notified that they are no longer invited to attend the hackathon. \\n* Participants will be passed to another participant.\\n* JPMC will pair teams based on technical skills listed on the application form. \\n* Participants will get to know team information at the start of the hackathon. \\n\\n**Data:**\\n* Participants agree to contribute any and all intellectual property and proprietary rights in and to the software, code, designs, materials, documentation, concepts, workflows and related items you write, create or develop in respect of your participation in and to the Hackathon and any other activities (\"Works\") into open source, under a project governed by a BSD or MIT license.\\n* Participants acknowledge that everything you develop, write, and create in your participation in the hackathon is your own work and is not the work of any third party.\\n* Participants further agree to keep confidential all information of a confidential nature or which is commercially sensitive.\\n\\nThe document also specifies the ARV (approximate retail value) of the electronic prizes awarded in the hackathon, which vary based on location:\\n\\n* **India:** One prize between INR 17,000 - 25,000 will be awarded to each individual member of the winning team(s) for the overall hackathon.\\n* **Singapore:** One prize between SGD 500-700 will be awarded each individual member of the winning team(s) for the overall hackathon, limited to one prize per person. \\n* **Hong Kong:** One prize between HKD 2400-3600 will be awarded each individual member of the winning team(s) for the overall hackathon, limited to one prize per person. \\n\\nTaxes, if any, are the sole responsibility of each winner. \\n', \"The provided image contains a text about the legal terms and conditions of a Hackathon organized by JPMC.  The terms are divided into sections namely, **JPMC's Policy**, **JPMC's Decisions**, **Governing Law**. The **Governing Law** section contains information about the jurisdiction and applicable laws for the Hackathon. The table lists the country and jurisdiction:\\n\\n| Country | Jurisdiction |\\n|---|---|\\n| US | These Rules and any contractual or non-contractual obligations arising out of or in relation to them or the Hackathon shall be governed by and construed in accordance with the laws of the State New York. All disputes arising out of or in relation to these Rules or the Hackathon or any non-contractual obligations arising out of or relating to these Rules or the Hackathon shall be submitted to the exclusive jurisdiction of the federal and state courts located in the laws of the State New York, and you agree and submit to the jurisdiction and venue of such courts. |\\n| Argentina | These Rules and any contractual or non-contractual obligations arising out of or in relation to them or the Hackathon shall be governed by and construed in accordance with the Argentinian laws. All disputes arising out of or in relation to these Rules or the Hackathon or any non-contractual obligations arising out of or relating to these Rules or the Hackathon shall be submitted to the exclusive jurisdiction of the commercial |\\n\\nThe document also states that JPMC will not be liable for any claim in respect of indirect loss, loss of profit, or consequential loss arising out of any act or omission committed by JPMC hereunder. Further, all participants/team members agree to release JPMC and its parents, affiliates, subsidiaries, officers, directors, employees, and all others associated with this Hackathon, from any and all liability with respect to, or in any way arising from this Hackathon, including liability for personal injury, damage or loss.\", 'The image is a table displaying legal jurisdiction information for the Hackathon in several countries. Each row represents a country and its legal jurisdiction regarding the Hackathon. The table is structured as follows:\\n\\n| Country | Legal Jurisdiction |\\n|---|---|\\n| UK | These Rules and any contractual or non-contractual obligations arising out of or in relation to them or the Hackathon shall be governed by and construed in accordance with English law. | \\n| Israel | All disputes arising out of or in relation to these Rules or the Hackathon or any non-contractual obligations arising out of or relating to these Rules or the Hackathon shall be submitted to the exclusive jurisdiction of the English Courts. |\\n| Ghana | These Rules and any contractual or non-contractual obligations arising out of or in relation to them or the Hackathon shall be governed by and construed in accordance with the applicable laws of India, without reference to the principles of conflicts of laws. |\\n| Nigeria | All disputes arising out of or in relation to these Rules or the Hackathon or any non-contractual obligations arising out of or relating to these Rules or the Hackathon shall be submitted to the exclusive jurisdiction of the courts of Mumbai. |\\n| Kenya | These Rules and any contractual or non-contractual obligations arising out of or in relation to them or the Hackathon shall be governed by and construed in accordance with the applicable laws of Singapore, without reference to the principles of conflicts of laws. |\\n| South Africa | All disputes arising out of or in relation to these Rules or the Hackathon or any non-contractual obligations arising out of or relating to these Rules or the Hackathon shall be submitted to the exclusive jurisdiction of the courts of Singapore. |\\n| India | These Rules and any contractual or non-contractual obligations arising out of or in relation to them or the Hackathon shall be governed by and construed in accordance with the laws of Hong Kong. |\\n| Singapore | All disputes arising out of or in relation to these Rules or the Hackathon or any non-contractual obligations arising out of or relating to these Rules or the Hackathon shall be submitted to the exclusive jurisdiction of the courts located in Hong Kong, and you agree and submit to the jurisdiction and venue of such courts. |\\n| Hong Kong | You agree that your participation in the Hackathon does not automatically give rise to an employment relationship with JPMC or the non-profit. |\\n\\n\\nThis table provides clear information on the legal framework governing the Hackathon in different countries. This information is crucial for understanding the legal implications and risks associated with participation in the Hackathon for individuals and organizations from diverse locations. \\n', 'The text in the image is a list of addresses for different branches of JP Morgan Chase Bank. \\n\\n- J.P. Morgan Chase Bank - Hong Kong Branch, Chater House, 8 Connaught Road Central, Hong Kong\\n- J.P. Morgan Chase Bank - Singapore Branch, 168 Robinson Road, Singapore\\n- J.P. Morgan Services Argentina S.R.L., Av. Belgrano 955, 1st Floor, C.A.B.A, Argentina\\n- J.P. Morgan Services India Private Limited, Prism Towers, Levels 9 to 11, Mindspace, Link Road, Goregaon (West), Mumbai 400 104, India\\n\\nThe text also states that JP Morgan Chase is an equal opportunity and affirmative action employer, disability/veteran.']\n",
      "    AI:\"\"\n",
      "    \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "CPU times: user 38.2 ms, sys: 15 ms, total: 53.2 ms\n",
      "Wall time: 5.25 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# que=start_quiz2('hard',pages,docs,0)\n",
    "que=start_quiz2('hard',docs,pages,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6f5bb2",
   "metadata": {},
   "source": [
    "# Part 2 of APP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a40dadb",
   "metadata": {},
   "source": [
    "# paragraph question Answering for University Exam prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "78979072",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.chains import SequentialChain\n",
    "# from fastapi import FastAPI\n",
    "# from langserve import add_routes\n",
    "import pdf2image \n",
    "from PIL import Image\n",
    "import google.generativeai as genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d06fdcaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['OPENAI_API_KEY']='OPEN_AI_API_KEY'\n",
    "os.environ['LANGCHAIN_API_KEY']='LANGCHAIN_API_KEY_HERE'\n",
    "os.environ['LANGCHAIN_TRACING_V2']='true'\n",
    "genai.configure(api_key='GEMINI_API_KEY_HERE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d485019b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt1=ChatPromptTemplate.from_messages(\n",
    "[\n",
    "    (\"system\",'''Your task is to act as \n",
    "    an Examiner, generate a single {diff_level} question based on \n",
    "    provided data. The user will then answer these \n",
    "    questions.\n",
    "    geneate relevant questions and the Student(whose is going to answer \n",
    "    that question) cannot see the provided data\n",
    "    donot generate questions like from the provided content answer\n",
    "    these.\n",
    "    also generate a unique question everytime'''),\n",
    "    (\"user\",'Content:{content}<previous questions>{previous_questions}</previous_questions>')\n",
    "]\n",
    ")\n",
    "prompt2=ChatPromptTemplate.from_messages(\n",
    "[\n",
    "    ('system','''You have to act as an Exam papers Evaluator.\n",
    "     you are Provided with a <question>{question}</question>and the content\n",
    "     from where the question is generated:<content>{content}</content>\n",
    "     \n",
    "     Please provide the questions in this format, structured as follows:\n",
    "     <Structure>\n",
    "\"Missing points\":\"\"\n",
    "\"Bluff Points\";\"\"\n",
    "\"Percentage Match\":\"\"\n",
    "\"Improved Answer\":\"\"\n",
    "</Structure>\n",
    "     based on the question and content ou will evaluate the answers based on the following criteria:\n",
    "\n",
    "Missing Points: Identify the points or keywords that are missing in the student's answer and suggest additions to improve the answer.\n",
    "Bluff Points: Identify points in the answer that are not relevant to the question asked.\n",
    "Percentage Match: Calculate the percentage of the answer that is correct based on the question.\n",
    "in the end also provide a better answer ,you can your knowledge\n",
    "also to make a better and improved answerlike this:-\n",
    "Improved answer:also provide a improved answer of around 100 words\n",
    "''')\n",
    "    ,\n",
    "    ('user','ANSWER:<answer>{answer}</answer>')\n",
    "]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bd081d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "para_llm=ChatOpenAI(temperature=0.5)\n",
    "# model = genai.GenerativeModel('gemini-pro-vision')\n",
    "output_parser=StrOutputParser()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "51c0b25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain1=LLMChain(llm=para_llm,prompt=prompt1,output_key='question',verbose=True)\n",
    "chain2=LLMChain(llm=para_llm,prompt=prompt2,verbose=True,output_key='result')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4a3170f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_from_image(image):\n",
    "    image.save('abc.jpg')\n",
    "    img=Image.open('abc.jpg')\n",
    "    res=model.generate_content(['''\n",
    "             Your task is to extract important text from pictures uploaded by users. \n",
    "             The pictures may contain flowcharts, diagrams, or any other relevant educational content. \n",
    "             The extracted text should be accurate and relevant for further processing.\n",
    "            \n",
    "            ''',img])\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f3177079",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text='''\n",
    "Players from the seven States ,\n",
    "Telangana, Andhra Pradesh, Tamil Nadu, \n",
    "Karnataka, Kerala, \\nMaharashtra and Odisha, besides \n",
    "some internationals will be in action.  \\n• For the first \n",
    "time in India, Carrom Live Platform will be paperless with \n",
    "the s cores to be entered \\nthrough mobiles, live scores and \n",
    "online statistics, besides live streaming.  \\nTelangana \n",
    "Launches State Robotics Framework  \\n• Telangana announced \n",
    "Robotics Framework   which would encompass creating an \n",
    "ecosystem for \\nrobotics that champions inno vation, \n",
    "entrepreneurship, and research and development, and set\n",
    "\\nup the Telangana Robotics Innovation Centre as a (TRIC) \n",
    "\\n• It is developed by Telangana’s Department of Information\n",
    "Technology’s Emerging Technologies \\nWing, in conjunction \n",
    "with the All India Robo tics Association'\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "1ddbbe10",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Your task is to act as \n",
      "    an Examiner, generate a single easy question based on \n",
      "    provided data. The user will then answer these \n",
      "    questions.\n",
      "    geneate relevant questions and the Student(whose is going to answer \n",
      "    that question) cannot see the provided data\n",
      "    donot generate questions like from the provided content answer\n",
      "    these.\n",
      "    also generate a unique question everytime\n",
      "Human: Content:\n",
      "Players from the seven States ,\n",
      "Telangana, Andhra Pradesh, Tamil Nadu, \n",
      "Karnataka, Kerala, \n",
      "Maharashtra and Odisha, besides \n",
      "some internationals will be in action.  \n",
      "• For the first \n",
      "time in India, Carrom Live Platform will be paperless with \n",
      "the s cores to be entered \n",
      "through mobiles, live scores and \n",
      "online statistics, besides live streaming.  \n",
      "Telangana \n",
      "Launches State Robotics Framework  \n",
      "• Telangana announced \n",
      "Robotics Framework   which would encompass creating an \n",
      "ecosystem for \n",
      "robotics that champions inno vation, \n",
      "entrepreneurship, and research and development, and set\n",
      "\n",
      "up the Telangana Robotics Innovation Centre as a (TRIC) \n",
      "\n",
      "• It is developed by Telangana’s Department of Information\n",
      "Technology’s Emerging Technologies \n",
      "Wing, in conjunction \n",
      "with the All India Robo tics Association'),\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "x=chain1.invoke({'diff_level':'easy','content':input_text})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "71cff65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ans='''\n",
    "Telangana announced the launch of a State Robotics Framework \n",
    "to promote innovation, entrepreneurship, and research \n",
    "and development in the field of robotics. This framework \n",
    "includes creating an ecosystem for robotics and setting \n",
    "up the Telangana Robotics Innovation Centre (TRIC). \n",
    "It is developed by Telangana’s Department of Information \n",
    "Technology’s Emerging Technologies Wing, in \n",
    "conjunction with the All India Robotics Association.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "8ee1f7cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You have to act as an Exam papers Evaluator.\n",
      "     you are Provided with a {'diff_level': 'easy', 'content': \"\\nPlayers from the seven States ,\\nTelangana, Andhra Pradesh, Tamil Nadu, \\nKarnataka, Kerala, \\nMaharashtra and Odisha, besides \\nsome internationals will be in action.  \\n• For the first \\ntime in India, Carrom Live Platform will be paperless with \\nthe s cores to be entered \\nthrough mobiles, live scores and \\nonline statistics, besides live streaming.  \\nTelangana \\nLaunches State Robotics Framework  \\n• Telangana announced \\nRobotics Framework   which would encompass creating an \\necosystem for \\nrobotics that champions inno vation, \\nentrepreneurship, and research and development, and set\\n\\nup the Telangana Robotics Innovation Centre as a (TRIC) \\n\\n• It is developed by Telangana’s Department of Information\\nTechnology’s Emerging Technologies \\nWing, in conjunction \\nwith the All India Robo tics Association'),\\n\", 'question': 'Question:\\nWhich Indian state recently launched a Robotics Framework to promote innovation, entrepreneurship, and research and development in the field of robotics?'} and the content\n",
      "     from where the question is generated:\n",
      "Players from the seven States ,\n",
      "Telangana, Andhra Pradesh, Tamil Nadu, \n",
      "Karnataka, Kerala, \n",
      "Maharashtra and Odisha, besides \n",
      "some internationals will be in action.  \n",
      "• For the first \n",
      "time in India, Carrom Live Platform will be paperless with \n",
      "the s cores to be entered \n",
      "through mobiles, live scores and \n",
      "online statistics, besides live streaming.  \n",
      "Telangana \n",
      "Launches State Robotics Framework  \n",
      "• Telangana announced \n",
      "Robotics Framework   which would encompass creating an \n",
      "ecosystem for \n",
      "robotics that champions inno vation, \n",
      "entrepreneurship, and research and development, and set\n",
      "\n",
      "up the Telangana Robotics Innovation Centre as a (TRIC) \n",
      "\n",
      "• It is developed by Telangana’s Department of Information\n",
      "Technology’s Emerging Technologies \n",
      "Wing, in conjunction \n",
      "with the All India Robo tics Association'),\n",
      "\n",
      "     based on the question and content ou will evaluate the answers based on the following criteria:\n",
      "\n",
      "Missing Points: Identify the points or keywords that are missing in the student's answer and suggest additions to improve the answer.\n",
      "Bluff Points: Identify points in the answer that are not relevant to the question asked.\n",
      "Percentage Match: Calculate the percentage of the answer that is correct based on the question.\n",
      "in the end also provide a better answer ,you can your knowledge\n",
      "also to make a better and improved answerlike this:-\n",
      "Improved answer:also provide a improved answer\n",
      "\n",
      "Human: ANSWER:\n",
      "Telangana announced the launch of a State Robotics Framework \n",
      "to promote innovation, entrepreneurship, and research \n",
      "and development in the field of robotics. This framework \n",
      "includes creating an ecosystem for robotics and setting \n",
      "up the Telangana Robotics Innovation Centre (TRIC). \n",
      "It is developed by Telangana’s Department of Information \n",
      "Technology’s Emerging Technologies Wing, in \n",
      "conjunction with the All India Robotics Association.\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "y=chain2.invoke({'content':input_text,'question':x,'answer':ans})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "ab85c9f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Points:\n",
      "1. The student's answer is missing the mention of Telangana as the Indian state that recently launched the Robotics Framework.\n",
      "2. The student did not mention that the framework aims to promote innovation, entrepreneurship, and research and development in robotics.\n",
      "3. The student did not include the detail about the Telangana Robotics Innovation Centre (TRIC) being set up as part of this initiative.\n",
      "\n",
      "Bluff Points:\n",
      "There are no bluff points in the student's answer.\n",
      "\n",
      "Percentage Match:\n",
      "The student's answer covers about 85% of the information provided in the question.\n",
      "\n",
      "Improved answer:\n",
      "Telangana recently launched a State Robotics Framework to foster innovation, entrepreneurship, and research and development in the field of robotics. This framework aims to create an ecosystem that supports robotics and has led to the establishment of the Telangana Robotics Innovation Centre (TRIC). Developed by Telangana’s Department of Information Technology’s Emerging Technologies Wing in collaboration with the All India Robotics Association, this initiative signifies a significant step towards advancing robotics technology in the region.\n"
     ]
    }
   ],
   "source": [
    "print(y['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2880d1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "para_content =None\n",
    "page_numbers=[]\n",
    "para_questions=[]\n",
    "def gen_ques(pages,level,para_questions):\n",
    "    global para_content\n",
    "    prque=''\n",
    "    page_numbers.clear()\n",
    "#     texts=split_text(docs)\n",
    "    for i in range(0,3):\n",
    "        if len(pages)>2:\n",
    "            ind = random.randint(0, len(pages) - 1)\n",
    "            page_numbers.append(ind)\n",
    "            para_content = pages[ind]\n",
    "            x = chain1.invoke({'diff_level': level, 'content':para_content,'previous_questions':prque})\n",
    "        else:\n",
    "            x = chain1.invoke({'diff_level': level, 'content':pages,'previous_questions':prque})\n",
    "        prque=prque+x['question']+'\\n'\n",
    "        para_questions.append({'id':i,'answered':0,'question':x['question'],'chosen':''})\n",
    "        print(page_numbers)\n",
    "    return para_questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5e39c3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_ans(pages,user_ans):\n",
    "    result=[]\n",
    "# user_ans=json.loads(user_ans)\n",
    "    for i in range(3):\n",
    "        que=(user_ans[i])['question']\n",
    "        ans=(user_ans[i])['chosen']\n",
    "        if(len(pages)>2):\n",
    "            output=(chain2.invoke({'content':pages[page_numbers[i]],'question':que,'answer':ans}))['result']\n",
    "        else:\n",
    "             output=(chain2.invoke({'content':pages,'question':que,'answer':ans}))['result']\n",
    "        print(output)\n",
    "        output=output.replace('\\n','<br></br>')\n",
    "        output='Q. '+que+'<br></br>'+output\n",
    "        result.append({'result':output})\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "97e29fd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Your task is to act as \n",
      "    an Examiner, generate a single hard question based on \n",
      "    provided data. The user will then answer these \n",
      "    questions.\n",
      "    geneate relevant questions and the Student(whose is going to answer \n",
      "    that question) cannot see the provided data\n",
      "    donot generate questions like from the provided content answer\n",
      "    these.\n",
      "    also generate a unique question everytime\n",
      "Human: Content:The image contains a list of J.P. Morgan Chase Bank branches:\n",
      "\n",
      "* J.P. Morgan Chase Bank - Hong Kong Branch, Chater House, 8 Connaught Road Central, Hong Kong\n",
      "* J.P. Morgan Chase Bank - Singapore Branch, 168 Robinson Road, Singapore\n",
      "* J.P. Morgan Services Argentina S.R.L., Av. Belgrano 955, 1st Floor, C.A.B.A, Argentina\n",
      "* J.P. Morgan Services India Private Limited, Prism Towers, Levels 9 to 11, Mindpace, Link Road, Goregaon (West), Mumbai 400 104, India\n",
      "\n",
      "©2024 JPMorgan Chase & Co. JPMorgan Chase is an equal opportunity and affirmative action employer Disability/Veteran<previous questions></previous_questions>\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "[3]\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Your task is to act as \n",
      "    an Examiner, generate a single hard question based on \n",
      "    provided data. The user will then answer these \n",
      "    questions.\n",
      "    geneate relevant questions and the Student(whose is going to answer \n",
      "    that question) cannot see the provided data\n",
      "    donot generate questions like from the provided content answer\n",
      "    these.\n",
      "    also generate a unique question everytime\n",
      "Human: Content:The provided image is a legal document outlining the terms and conditions for participating in a Hackathon organized by JPMC. It highlights the following key aspects:\n",
      "\n",
      "**Privacy Policy:** JPMC emphasizes its commitment to complying with all applicable privacy laws and regulations. They may share personal information with third-party vendors solely for providing access to the platform, but will not share photos or videos taken at the Hackathon without consent.\n",
      "\n",
      "**Image Usage:** Participants agree to the use of their images and videos for promotional purposes, including on the internet, in print, and in broadcasts. \n",
      "\n",
      "**JPMC's Responsibilities:** JPMC's decisions regarding the Hackathon, including prize awards, are final. They are not liable for indirect loss, loss of profit, or consequential losses arising out of any act or omission committed by JPMC or its associated parties.\n",
      "\n",
      "**Governing Law and Jurisdiction:** The terms and conditions are governed by and construed in accordance with the laws of the State of New York (for US participants) or the Argentinian laws (for Argentinian participants). All disputes will be submitted to the exclusive jurisdiction of the respective courts. \n",
      "\n",
      "**Disclaimer:** The document clarifies that JPMC is not liable for any claim in respect of indirect loss, loss of profit, or any special or consequential loss arising out of any act or omission committed by JPMC or its associated parties. \n",
      "\n",
      "**Key Takeaways:**\n",
      "\n",
      "- Participants grant JPMC permission to use their images and videos for publicity purposes.\n",
      "- JPMC reserves the right to make final decisions regarding the Hackathon and its outcomes. \n",
      "- The legal jurisdiction for disputes arising from the Hackathon is defined based on the participant's country of origin.\n",
      "- Participants agree to release JPMC and its associated parties from liability for any and all losses arising from the Hackathon. \n",
      "<previous questions>What are the addresses of J.P. Morgan Chase Bank branches in Hong Kong, Singapore, Argentina, and India?\n",
      "</previous_questions>\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "[3, 1]\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Your task is to act as \n",
      "    an Examiner, generate a single hard question based on \n",
      "    provided data. The user will then answer these \n",
      "    questions.\n",
      "    geneate relevant questions and the Student(whose is going to answer \n",
      "    that question) cannot see the provided data\n",
      "    donot generate questions like from the provided content answer\n",
      "    these.\n",
      "    also generate a unique question everytime\n",
      "Human: Content:##  JPMorgan Chase Code for Good Hackathon 2024 Official Rules\n",
      "\n",
      "This document outlines the official rules for the JPMorgan Chase Code for Good Hackathon 2024.\n",
      "\n",
      "**Eligibility:**\n",
      "* Open to participating universities only. \n",
      "* Students must check with their placement office to confirm their university's eligibility.\n",
      "\n",
      "**About the Event:**\n",
      "* Teams of students will compete against each other on behalf of a charity assigned to them.\n",
      "* The goal is to develop a technological solution to a problem faced by the charity.\n",
      "* **JPMC (JPMorgan Chase Bank, N.A.)** will judge the solutions and award prizes to the teams who make the best attempt at developing a solution, in their opinion.\n",
      "* **JPMC reserves the right to change any prize at its discretion.**\n",
      "\n",
      "**Important Considerations:**\n",
      "* All entries become the exclusive property of JPMC and will not be acknowledged or returned.\n",
      "* Participants agree to be bound by the **Hackathon Official Rules (\"Rules\")** and the decisions of the judges, which shall be final, binding and conclusive on all matters. \n",
      "* The health and wellbeing of each team member is extremely important to JPMC. \n",
      "* If you require an accommodation for a medical condition, please contact JPMC Security.\n",
      "* JPMC hereby disclaims any liability relating to any injury arising from a pre-existing medical condition or a request for any requisite facilities and any subsequent injury, illness or harm arising from such condition or lack of facilities. \n",
      "\n",
      "**Prizes:**\n",
      "\n",
      "| Region/Country | Prizes |\n",
      "|---|---|\n",
      "| North America | One (1) prize between $300-$500 in value will be awarded each individual member of the winning team(s) for the overall Hackathon. **Approximate Retail Value (\"ARV\")** of all prizes: An average of $3000 for the overall winning team(s) members. The ARV of electronic prizes is subject to price fluctuations in the consumer marketplace based on, among other things, any gap in time between the date the ARV is determined for purposes of these Official Rules and the date the prize is awarded. Any difference between stated ARV and the actual price of the electronic prize will not be awarded. Taxes, if any, are the sole responsibility of each winner. Limit one (1) prize per person. |\n",
      "| Argentina | One (1) prize between $300 USD - $500 USD in value will be awarded each individual member of the winning team(s) for the overall Hackathon. Taxes, if any, are the sole responsibility of each winner. Limit one (1) prize per person. |\n",
      "| Europe, Middle East and Africa | One (1) prize between £300-£400 in value will be awarded to each individual member of the winning team(s) for the overall challenge. **The Approximate Retail Value (\"ARV\")** of all prizes is intended to be: A total of £2400 for the overall winning team(s) members. The |\n",
      "\n",
      "**Important Tax Information:** \n",
      "* The fair market value of any prizes, and any other amounts paid by JPMC under the terms of the Code for Good program, may be considered miscellaneous income received from JPMC and may be reportable to you and the IRS on Form 1099-MISC for the year in which they are awarded or paid. \n",
      "* You are responsible for any tax liability related to participating in the program. \n",
      "* Please consult your own tax advisor if you have any questions about your personal tax situation. \n",
      "<previous questions>What are the addresses of J.P. Morgan Chase Bank branches in Hong Kong, Singapore, Argentina, and India?\n",
      "What are the specific consequences outlined in the document for participants who do not comply with the terms and conditions of the Hackathon organized by JPMC?\n",
      "</previous_questions>\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "[3, 1, 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'id': 0,\n",
       "  'answered': 0,\n",
       "  'question': 'What are the addresses of J.P. Morgan Chase Bank branches in Hong Kong, Singapore, Argentina, and India?',\n",
       "  'chosen': ''},\n",
       " {'id': 1,\n",
       "  'answered': 0,\n",
       "  'question': 'What are the specific consequences outlined in the document for participants who do not comply with the terms and conditions of the Hackathon organized by JPMC?',\n",
       "  'chosen': ''},\n",
       " {'id': 2,\n",
       "  'answered': 0,\n",
       "  'question': 'Question: How does JPMC ensure the fairness and impartiality of the judging process in the Code for Good Hackathon 2024, considering the potential impact of prize awards on participants from different regions/countries?',\n",
       "  'chosen': ''}]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_ques(pages,'hard',para_questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4a687b3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 0,\n",
       "  'answered': 0,\n",
       "  'question': 'Question: In what ways does J.P. Morgan Chase demonstrate its commitment to diversity and inclusion in its employment practices?',\n",
       "  'chosen': ''},\n",
       " {'id': 1,\n",
       "  'answered': 0,\n",
       "  'question': 'Question: In the context of the Hackathon, why is it important to clarify that participation does not automatically result in an employment relationship with JPMC or the non-profit organization?',\n",
       "  'chosen': ''},\n",
       " {'id': 2,\n",
       "  'answered': 0,\n",
       "  'question': 'Question: In the context of the Hackathon, what are the key points highlighted regarding jurisdiction for disputes in different countries and the relationship between participation in the event and employment with JPMC or the non-profit?',\n",
       "  'chosen': ''}]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "para_questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "2b7e0da8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 1, 0]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page_numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "12a4bb6a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You have to act as an Exam papers Evaluator.\n",
      "     you are Provided with a What are some key skills expected from participants of \"Code for Good\" 2024 event organized by JPMorgan Chase? and the content\n",
      "     from where the question is generated:The document is a call for participation in \"Code for Good\" 2024. The event is organized by JPMorgan Chase and is aimed at bringing together tech talent to address social problems. The event will take place in Bengaluru, Hyderabad and Mumbai.\n",
      "\n",
      "The event is open to 2025 batch graduates with a Bachelor's degree in Computer Science, Information Science or Information Technology. Participants should have a minimum aggregate of 8.5 CGPA until the date of engineering course completion.  \n",
      "\n",
      "The event will require participants to apply online within the given deadline. Selected participants will be notified via email with final event details. Participants will be required to bring their laptops to the event.\n",
      "\n",
      "Participants will be working in teams alongside JPMorgan Chase technologists. They will be working on creating solutions for real-world problems faced by social organizations. The event gives participants the chance to see whether a career in financial services technology is for them. Participants will be learning from their experience as they creatively solve real-world problems faced by social organizations. The goal is to come up with cutting-edge ideas that could make a difference to the people who need it most. \n",
      "\n",
      "Key skills expected are knowledge of programming languages like Java, Python, JavaScript, Go and other programming languages, networks and databases. Participants should also have strong interpersonal and communication skills. Fluency in English is essential.\n",
      "\n",
      "For inquiries, one can email at code.for.good@jpmorgan.com. \n",
      "\n",
      "     Please provide the questions in JSON format, structured as follows:\n",
      "\"Missing points\":\"\"\n",
      "\"Bluff Points\";\"\"\n",
      "\"Percentage Match\":\"\"\n",
      "\"Improved Answer\":\"\"\n",
      "     based on the question and content ou will evaluate the answers based on the following criteria:\n",
      "\n",
      "Missing Points: Identify the points or keywords that are missing in the student's answer and suggest additions to improve the answer.\n",
      "Bluff Points: Identify points in the answer that are not relevant to the question asked.\n",
      "Percentage Match: Calculate the percentage of the answer that is correct based on the question.\n",
      "in the end also provide a better answer ,you can your knowledge\n",
      "also to make a better and improved answerlike this:-\n",
      "Improved answer:also provide a improved answer\n",
      "\n",
      "Human: ANSWER:hi hello bye\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Missing Points: \n",
      "- Key skills expected from participants of \"Code for Good\" 2024 event\n",
      "- Knowledge of programming languages like Java, Python, JavaScript, Go and other programming languages\n",
      "- Strong interpersonal and communication skills\n",
      "- Fluency in English\n",
      "\n",
      "Bluff Points:\n",
      "- The answer provided does not address the key skills expected from participants of the event.\n",
      "\n",
      "Percentage Match: 0%\n",
      "\n",
      "Improved Answer:\n",
      "The key skills expected from participants of \"Code for Good\" 2024 event organized by JPMorgan Chase include knowledge of programming languages like Java, Python, JavaScript, Go, and other programming languages, as well as networks and databases. Additionally, participants should possess strong interpersonal and communication skills, along with fluency in English.\n"
     ]
    }
   ],
   "source": [
    "# gen_ques('./cell_guide.pdf','medium')\n",
    "print(check_ans(que,'hi hello bye'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f188e16",
   "metadata": {},
   "source": [
    "# Part 3 User Asking Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "a97927ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize global variables\n",
    "vector_db = None\n",
    "docs = None\n",
    "level = None\n",
    "para_que = None\n",
    "pages=None\n",
    "token_user={}\n",
    "Multi_quiz_questions=None\n",
    "user1={}\n",
    "user2={}\n",
    "image_desc=None\n",
    "para_pages=None\n",
    "quiz_pages=None\n",
    "chatbot_docs=None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a7bf77",
   "metadata": {},
   "source": [
    "# Flask Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "1ce4670e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:5000\n",
      " * Running on http://192.168.1.13:5000\n",
      "Press CTRL+C to quit\n",
      "192.168.1.15 - - [03/Jun/2024 16:14:29] \"OPTIONS /askQuery HTTP/1.1\" 200 -\n",
      "192.168.1.15 - - [03/Jun/2024 16:14:29] \"OPTIONS /askQuery HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE1\n",
      "DONE1\n",
      "page1done\n",
      "page1done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-06-03 16:14:42,380] ERROR in app: Exception on /askQuery [POST]\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/mac/anaconda3/lib/python3.11/site-packages/flask/app.py\", line 2525, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mac/anaconda3/lib/python3.11/site-packages/flask/app.py\", line 1822, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mac/anaconda3/lib/python3.11/site-packages/flask_cors/extension.py\", line 176, in wrapped_function\n",
      "    return cors_after_request(app.make_response(f(*args, **kwargs)))\n",
      "                                                ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mac/anaconda3/lib/python3.11/site-packages/flask/app.py\", line 1820, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mac/anaconda3/lib/python3.11/site-packages/flask/app.py\", line 1796, in dispatch_request\n",
      "    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/pd/qtz24m7907db4zd40wq0yv940000gn/T/ipykernel_712/300045174.py\", line 128, in askQuery\n",
      "    vector_db, docs, pages = extract_data(link)\n",
      "                             ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/pd/qtz24m7907db4zd40wq0yv940000gn/T/ipykernel_712/3248492033.py\", line 12, in extract_data\n",
      "    db,docs,pages=extract_text('./main.pdf')\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/pd/qtz24m7907db4zd40wq0yv940000gn/T/ipykernel_712/4146490283.py\", line 2, in extract_text\n",
      "    pages=pdf_to_text(pdf_path)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/pd/qtz24m7907db4zd40wq0yv940000gn/T/ipykernel_712/2577321615.py\", line 6, in pdf_to_text\n",
      "    img=Image.open('page.jpg')\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mac/anaconda3/lib/python3.11/site-packages/PIL/Image.py\", line 3339, in open\n",
      "    raise UnidentifiedImageError(msg)\n",
      "PIL.UnidentifiedImageError: cannot identify image file '/Users/mac/Desktop/langchain/page.jpg'\n",
      "192.168.1.15 - - [03/Jun/2024 16:14:42] \"POST /askQuery HTTP/1.1\" 500 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page2done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "192.168.1.15 - - [03/Jun/2024 16:14:48] \"POST /askQuery HTTP/1.1\" 200 -\n",
      "192.168.1.15 - - [03/Jun/2024 16:15:08] \"OPTIONS /askQuery HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Rating': -1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "192.168.1.15 - - [03/Jun/2024 16:15:10] \"POST /askQuery HTTP/1.1\" 200 -\n",
      "192.168.1.15 - - [03/Jun/2024 16:15:15] \"OPTIONS /askQuery HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Rating': 1}\n",
      "\"What is a cell?\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "192.168.1.15 - - [03/Jun/2024 16:15:20] \"POST /askQuery HTTP/1.1\" 200 -\n",
      "192.168.1.15 - - [03/Jun/2024 16:15:33] \"OPTIONS /askQuery HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Rating': 1}\n",
      "\"What is a plant cell?\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "192.168.1.15 - - [03/Jun/2024 16:15:37] \"POST /askQuery HTTP/1.1\" 200 -\n",
      "192.168.1.15 - - [03/Jun/2024 16:15:48] \"OPTIONS /askQuery HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Rating': 1}\n",
      "\"What is an animal cell?\"\n",
      "{'Rating': 1}\n",
      "\"What is an animal cell?\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "192.168.1.15 - - [03/Jun/2024 16:15:52] \"POST /askQuery HTTP/1.1\" 200 -\n",
      "192.168.1.15 - - [03/Jun/2024 16:15:53] \"POST /askQuery HTTP/1.1\" 200 -\n",
      "192.168.1.15 - - [03/Jun/2024 16:16:16] \"OPTIONS /askQuery HTTP/1.1\" 200 -\n",
      "192.168.1.15 - - [03/Jun/2024 16:16:16] \"OPTIONS /askQuery HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE1\n",
      "DONE1\n",
      "page1done\n",
      "page1done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-06-03 16:16:28,031] ERROR in app: Exception on /askQuery [POST]\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/mac/anaconda3/lib/python3.11/site-packages/flask/app.py\", line 2525, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mac/anaconda3/lib/python3.11/site-packages/flask/app.py\", line 1822, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mac/anaconda3/lib/python3.11/site-packages/flask_cors/extension.py\", line 176, in wrapped_function\n",
      "    return cors_after_request(app.make_response(f(*args, **kwargs)))\n",
      "                                                ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mac/anaconda3/lib/python3.11/site-packages/flask/app.py\", line 1820, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mac/anaconda3/lib/python3.11/site-packages/flask/app.py\", line 1796, in dispatch_request\n",
      "    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/pd/qtz24m7907db4zd40wq0yv940000gn/T/ipykernel_712/300045174.py\", line 129, in askQuery\n",
      "    vector_db=add_to_db(docs)\n",
      "              ^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/pd/qtz24m7907db4zd40wq0yv940000gn/T/ipykernel_712/1697659785.py\", line 3, in add_to_db\n",
      "    faiss_db = Chroma.from_documents(docs,OpenAIEmbeddings())\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mac/anaconda3/lib/python3.11/site-packages/langchain_community/vectorstores/chroma.py\", line 778, in from_documents\n",
      "    return cls.from_texts(\n",
      "           ^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mac/anaconda3/lib/python3.11/site-packages/langchain_community/vectorstores/chroma.py\", line 736, in from_texts\n",
      "    chroma_collection.add_texts(\n",
      "  File \"/Users/mac/anaconda3/lib/python3.11/site-packages/langchain_community/vectorstores/chroma.py\", line 324, in add_texts\n",
      "    self._collection.upsert(\n",
      "  File \"/Users/mac/anaconda3/lib/python3.11/site-packages/chromadb/api/models/Collection.py\", line 477, in upsert\n",
      "    ) = self._validate_embedding_set(\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mac/anaconda3/lib/python3.11/site-packages/chromadb/api/models/Collection.py\", line 545, in _validate_embedding_set\n",
      "    valid_ids = validate_ids(maybe_cast_one_to_many_ids(ids))\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mac/anaconda3/lib/python3.11/site-packages/chromadb/api/types.py\", line 228, in validate_ids\n",
      "    raise ValueError(f\"Expected IDs to be a non-empty list, got {ids}\")\n",
      "ValueError: Expected IDs to be a non-empty list, got []\n",
      "192.168.1.15 - - [03/Jun/2024 16:16:28] \"POST /askQuery HTTP/1.1\" 500 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page2done\n",
      "page2done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "192.168.1.15 - - [03/Jun/2024 16:16:31] \"POST /askQuery HTTP/1.1\" 200 -\n",
      "192.168.1.15 - - [03/Jun/2024 16:16:45] \"OPTIONS /askQuery HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Rating': -1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "192.168.1.15 - - [03/Jun/2024 16:16:47] \"POST /askQuery HTTP/1.1\" 200 -\n",
      "192.168.1.15 - - [03/Jun/2024 16:17:17] \"OPTIONS /askQuery HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Rating': 1}\n",
      "\"What is a cell?\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "192.168.1.15 - - [03/Jun/2024 16:17:21] \"POST /askQuery HTTP/1.1\" 200 -\n",
      "192.168.1.15 - - [03/Jun/2024 16:17:57] \"OPTIONS /askQuery HTTP/1.1\" 200 -\n",
      "192.168.1.15 - - [03/Jun/2024 16:17:57] \"OPTIONS /askQuery HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE1\n",
      "DONE1\n",
      "page1done\n",
      "page1done\n",
      "page2done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "192.168.1.15 - - [03/Jun/2024 16:18:09] \"POST /askQuery HTTP/1.1\" 200 -\n",
      "[2024-06-03 16:18:10,761] ERROR in app: Exception on /askQuery [POST]\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/mac/anaconda3/lib/python3.11/site-packages/flask/app.py\", line 2525, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mac/anaconda3/lib/python3.11/site-packages/flask/app.py\", line 1822, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mac/anaconda3/lib/python3.11/site-packages/flask_cors/extension.py\", line 176, in wrapped_function\n",
      "    return cors_after_request(app.make_response(f(*args, **kwargs)))\n",
      "                                                ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mac/anaconda3/lib/python3.11/site-packages/flask/app.py\", line 1820, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mac/anaconda3/lib/python3.11/site-packages/flask/app.py\", line 1796, in dispatch_request\n",
      "    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/pd/qtz24m7907db4zd40wq0yv940000gn/T/ipykernel_712/300045174.py\", line 129, in askQuery\n",
      "    vector_db=add_to_db(docs)\n",
      "              ^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/pd/qtz24m7907db4zd40wq0yv940000gn/T/ipykernel_712/1697659785.py\", line 3, in add_to_db\n",
      "    faiss_db = Chroma.from_documents(docs,OpenAIEmbeddings())\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mac/anaconda3/lib/python3.11/site-packages/langchain_community/vectorstores/chroma.py\", line 778, in from_documents\n",
      "    return cls.from_texts(\n",
      "           ^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mac/anaconda3/lib/python3.11/site-packages/langchain_community/vectorstores/chroma.py\", line 736, in from_texts\n",
      "    chroma_collection.add_texts(\n",
      "  File \"/Users/mac/anaconda3/lib/python3.11/site-packages/langchain_community/vectorstores/chroma.py\", line 324, in add_texts\n",
      "    self._collection.upsert(\n",
      "  File \"/Users/mac/anaconda3/lib/python3.11/site-packages/chromadb/api/models/Collection.py\", line 477, in upsert\n",
      "    ) = self._validate_embedding_set(\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mac/anaconda3/lib/python3.11/site-packages/chromadb/api/models/Collection.py\", line 545, in _validate_embedding_set\n",
      "    valid_ids = validate_ids(maybe_cast_one_to_many_ids(ids))\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mac/anaconda3/lib/python3.11/site-packages/chromadb/api/types.py\", line 228, in validate_ids\n",
      "    raise ValueError(f\"Expected IDs to be a non-empty list, got {ids}\")\n",
      "ValueError: Expected IDs to be a non-empty list, got []\n",
      "192.168.1.15 - - [03/Jun/2024 16:18:10] \"POST /askQuery HTTP/1.1\" 500 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page2done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "192.168.1.15 - - [03/Jun/2024 16:18:54] \"OPTIONS /askQuery HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Rating': -1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "192.168.1.15 - - [03/Jun/2024 16:18:55] \"POST /askQuery HTTP/1.1\" 200 -\n",
      "192.168.1.15 - - [03/Jun/2024 16:19:15] \"OPTIONS /askQuery HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Rating': -1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "192.168.1.15 - - [03/Jun/2024 16:19:17] \"POST /askQuery HTTP/1.1\" 200 -\n",
      "192.168.1.15 - - [03/Jun/2024 16:19:35] \"OPTIONS /websearch HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Rating': 1}\n",
      "called\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "I will search for 'What is a cell?' and write an answer based on the results.\n",
      "{'tool_name': 'tavily_search_results_json', 'parameters': {'query': 'What is a cell?'}}\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m[{'url': 'https://www.khanacademy.org/science/biology/structure-of-a-cell/introduction-to-cells/a/intro-to-cells', 'content': 'Learn what cells are, how they were discovered, and why they are the basic units of life. Explore the history of cell theory and the diversity of cell types and shapes.'}, {'url': 'https://en.wikipedia.org/wiki/Cell_(biology)', 'content': \"The cell is the basic structural and functional unit of all forms of life. Every cell consists of cytoplasm enclosed within a membrane; many cells contain organelles, each with a specific function. The term comes from the Latin word cellula meaning 'small room'.\"}, {'url': 'https://www.nature.com/scitable/topicpage/what-is-a-cell-14023083/', 'content': 'A cell is the basic unit of life, surrounded by a membrane that controls what enters and exits. Cells contain various molecules and organelles that perform different functions, such as energy production, genetic expression, and communication.'}, {'url': 'https://www.britannica.com/science/cell-biology', 'content': 'Organelles include mitochondria, which are responsible for the energy transactions necessary for cell survival; lysosomes, which digest unwanted materials within the cell; and the endoplasmic reticulum and the Golgi apparatus, which play important roles in the internal organization of the cell by synthesizing selected molecules and then processing, sorting, and directing them to their proper locations. The cytosol contains an organized framework of fibrous molecules that constitute the cytoskeleton, which gives a cell its shape, enables organelles to move within the cell, and provides a mechanism by which the cell itself can move. The smallest known cells are a group of tiny bacteria called mycoplasmas; some of these single-celled organisms are spheres as small as 0.2 μm in diameter (1μm = about 0.000039 inch), with a total mass of 10−14 gram—equal to that of 8,000,000,000 hydrogen atoms. Certain proteins in the cell membrane are involved with cell-to-cell communication and help the cell to respond to changes in its environment.\\n In 1839 German physiologist\\xa0Theodor Schwann\\xa0and German botanist\\xa0Matthias Schleiden\\xa0promulgated that cells are the “elementary particles of organisms” in both plants and animals and recognized that some organisms are unicellular and others multicellular.\\xa0'}, {'url': 'https://biologydictionary.net/cell/', 'content': \"A cell is the basic unit of life that performs all of life's functions. Learn about the two major types of cells, prokaryotes and eukaryotes, and their subcategories, characteristics, and examples.\"}]\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "192.168.1.15 - - [03/Jun/2024 16:19:56] \"POST /websearch HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mRelevant Documents: 1,2,3,4\n",
      "Cited Documents: 1,2,3,4\n",
      "Answer: A cell is the basic unit of life, surrounded by a membrane that controls what enters and exits. Cells contain various molecules and organelles that perform different functions, such as energy production, genetic expression, and communication. The term 'cell' comes from the Latin word 'cellula', meaning 'small room'.\n",
      "Grounded answer: A cell is the <co: 1,2,4>basic unit of life</co: 1,2,4>, <co: 2>surrounded by a</co: 2> <co: 1,2>membrane</co: 1,2> that <co: 2>controls what enters and exits</co: 2>. Cells contain <co: 2>various molecules</co: 2> and <co: 1,2,3>organelles</co: 1,2,3> that <co: 2>perform different functions</co: 2>, such as <co: 2,3>energy production</co: 2,3>, <co: 2>genetic expression</co: 2>, and <co: 2,3>communication</co: 2,3>. The term 'cell' comes from the <co: 1>Latin word 'cellula</co: 1>', meaning <co: 1>'small room</co: 1>'.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "192.168.1.15 - - [03/Jun/2024 16:20:33] \"OPTIONS /askQuery HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Rating': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-06-03 16:20:34,856] ERROR in app: Exception on /askQuery [POST]\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/mac/anaconda3/lib/python3.11/site-packages/flask/app.py\", line 2525, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mac/anaconda3/lib/python3.11/site-packages/flask/app.py\", line 1822, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mac/anaconda3/lib/python3.11/site-packages/flask_cors/extension.py\", line 176, in wrapped_function\n",
      "    return cors_after_request(app.make_response(f(*args, **kwargs)))\n",
      "                                                ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mac/anaconda3/lib/python3.11/site-packages/flask/app.py\", line 1820, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mac/anaconda3/lib/python3.11/site-packages/flask/app.py\", line 1796, in dispatch_request\n",
      "    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/pd/qtz24m7907db4zd40wq0yv940000gn/T/ipykernel_712/300045174.py\", line 134, in askQuery\n",
      "    answer = query_check(query,vector_db,'local','Technical')\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/pd/qtz24m7907db4zd40wq0yv940000gn/T/ipykernel_712/4176353288.py\", line 15, in query_check\n",
      "    ans=ans_query(query,faiss_db,way)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/pd/qtz24m7907db4zd40wq0yv940000gn/T/ipykernel_712/128539316.py\", line 6, in ans_query\n",
      "    retriever=faiss_db.as_retriever()\n",
      "             ^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'NoneType' object has no attribute 'as_retriever'\n",
      "192.168.1.15 - - [03/Jun/2024 16:20:34] \"POST /askQuery HTTP/1.1\" 500 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"What can you tell me about HackerEarth?\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "192.168.1.15 - - [03/Jun/2024 16:21:10] \"OPTIONS /askQuery HTTP/1.1\" 200 -\n",
      "192.168.1.15 - - [03/Jun/2024 16:21:10] \"OPTIONS /askQuery HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE1\n",
      "DONE1\n",
      "page1done\n",
      "page1done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-06-03 16:21:22,440] ERROR in app: Exception on /askQuery [POST]\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/mac/anaconda3/lib/python3.11/site-packages/flask/app.py\", line 2525, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mac/anaconda3/lib/python3.11/site-packages/flask/app.py\", line 1822, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mac/anaconda3/lib/python3.11/site-packages/flask_cors/extension.py\", line 176, in wrapped_function\n",
      "    return cors_after_request(app.make_response(f(*args, **kwargs)))\n",
      "                                                ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mac/anaconda3/lib/python3.11/site-packages/flask/app.py\", line 1820, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mac/anaconda3/lib/python3.11/site-packages/flask/app.py\", line 1796, in dispatch_request\n",
      "    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/pd/qtz24m7907db4zd40wq0yv940000gn/T/ipykernel_712/300045174.py\", line 129, in askQuery\n",
      "    vector_db=add_to_db(docs)\n",
      "              ^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/pd/qtz24m7907db4zd40wq0yv940000gn/T/ipykernel_712/1697659785.py\", line 3, in add_to_db\n",
      "    faiss_db = Chroma.from_documents(docs,OpenAIEmbeddings())\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mac/anaconda3/lib/python3.11/site-packages/langchain_community/vectorstores/chroma.py\", line 778, in from_documents\n",
      "    return cls.from_texts(\n",
      "           ^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mac/anaconda3/lib/python3.11/site-packages/langchain_community/vectorstores/chroma.py\", line 736, in from_texts\n",
      "    chroma_collection.add_texts(\n",
      "  File \"/Users/mac/anaconda3/lib/python3.11/site-packages/langchain_community/vectorstores/chroma.py\", line 324, in add_texts\n",
      "    self._collection.upsert(\n",
      "  File \"/Users/mac/anaconda3/lib/python3.11/site-packages/chromadb/api/models/Collection.py\", line 477, in upsert\n",
      "    ) = self._validate_embedding_set(\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mac/anaconda3/lib/python3.11/site-packages/chromadb/api/models/Collection.py\", line 545, in _validate_embedding_set\n",
      "    valid_ids = validate_ids(maybe_cast_one_to_many_ids(ids))\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mac/anaconda3/lib/python3.11/site-packages/chromadb/api/types.py\", line 228, in validate_ids\n",
      "    raise ValueError(f\"Expected IDs to be a non-empty list, got {ids}\")\n",
      "ValueError: Expected IDs to be a non-empty list, got []\n",
      "192.168.1.15 - - [03/Jun/2024 16:21:22] \"POST /askQuery HTTP/1.1\" 500 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page2done\n",
      "page2done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "192.168.1.15 - - [03/Jun/2024 16:21:25] \"POST /askQuery HTTP/1.1\" 200 -\n",
      "192.168.1.15 - - [03/Jun/2024 16:21:31] \"OPTIONS /askQuery HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Rating': -1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "192.168.1.15 - - [03/Jun/2024 16:21:32] \"POST /askQuery HTTP/1.1\" 200 -\n",
      "192.168.1.15 - - [03/Jun/2024 16:21:38] \"OPTIONS /askQuery HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Rating': 1}\n",
      "\"What is a cell?\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "192.168.1.15 - - [03/Jun/2024 16:21:42] \"POST /askQuery HTTP/1.1\" 200 -\n",
      "192.168.1.15 - - [03/Jun/2024 16:23:37] \"OPTIONS /websearch HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Rating': 1}\n",
      "called\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "I will search for \"What is a cell?\" and write an answer based on the results.\n",
      "{'tool_name': 'tavily_search_results_json', 'parameters': {'query': 'What is a cell?'}}\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m[{'url': 'https://byjus.com/biology/cells/', 'content': 'Cell Definition. \"A cell is defined as the smallest, basic unit of life that is responsible for all of life\\'s processes.\". Cells are the structural, functional, and biological units of all living beings. A cell can replicate itself independently. Hence, they are known as the building blocks of life .'}, {'url': 'https://en.wikipedia.org/wiki/Cell_(biology)', 'content': \"The cell is the basic structural and functional unit of all forms of life. Every cell consists of cytoplasm enclosed within a membrane; many cells contain organelles, each with a specific function. The term comes from the Latin word cellula meaning 'small room'.\"}, {'url': 'https://www.nature.com/scitable/topicpage/what-is-a-cell-14023083/', 'content': 'All cells evolved from a common ancestor and use the same kinds of carbon-based molecules. Learn how cell function depends on a diverse group of nucleic acids, proteins, lipids, and sugars.'}, {'url': 'https://biologydictionary.net/cell/', 'content': 'There are countless different functions that cells must perform to obtain energy and reproduce. Depending on the cell, examples of these functions can include photosynthesis, breaking down sugar, locomotion, copying its own DNA, allowing certain substances to pass through the cell membrane while keeping others out, etc.'}, {'url': 'https://www.britannica.com/science/cell-biology', 'content': 'Organelles include mitochondria, which are responsible for the energy transactions necessary for cell survival; lysosomes, which digest unwanted materials within the cell; and the endoplasmic reticulum and the Golgi apparatus, which play important roles in the internal organization of the cell by synthesizing selected molecules and then processing, sorting, and directing them to their proper locations. The cytosol contains an organized framework of fibrous molecules that constitute the cytoskeleton, which gives a cell its shape, enables organelles to move within the cell, and provides a mechanism by which the cell itself can move. The smallest known cells are a group of tiny bacteria called mycoplasmas; some of these single-celled organisms are spheres as small as 0.2 μm in diameter (1μm = about 0.000039 inch), with a total mass of 10−14 gram—equal to that of 8,000,000,000 hydrogen atoms. Certain proteins in the cell membrane are involved with cell-to-cell communication and help the cell to respond to changes in its environment.\\n In 1839 German physiologist\\xa0Theodor Schwann\\xa0and German botanist\\xa0Matthias Schleiden\\xa0promulgated that cells are the “elementary particles of organisms” in both plants and animals and recognized that some organisms are unicellular and others multicellular.\\xa0'}]\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "192.168.1.15 - - [03/Jun/2024 16:23:53] \"POST /websearch HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mRelevant Documents: 0,1,2,3,4\n",
      "Cited Documents: 0,1,2,3,4\n",
      "Answer: A cell is the smallest, basic unit of life and is responsible for all of life's processes. Cells are the structural, functional, and biological units of all living beings. They can replicate themselves independently and are therefore known as the building blocks of life. All cells evolved from a common ancestor and use the same kinds of carbon-based molecules. Every cell consists of cytoplasm enclosed within a membrane; many cells contain organelles, each with a specific function.\n",
      "Grounded answer: A cell is the <co: 0,1,4>smallest</co: 0,1,4>, <co: 0,1>basic unit of life</co: 0,1> and is <co: 0>responsible for all of life's processes</co: 0>. Cells are the <co: 0,1>structural, functional, and biological units of all living beings</co: 0,1>. They can <co: 0>replicate themselves independently</co: 0> and are therefore known as the <co: 0>building blocks of life</co: 0>. <co: 2>All cells evolved from a common ancestor</co: 2> and <co: 2>use the same kinds of carbon-based molecules</co: 2>. <co: 1>Every cell consists of cytoplasm enclosed within a membrane</co: 1>; <co: 1>many cells contain organelles</co: 1>, each with a <co: 1,3,4>specific function</co: 1,3,4>.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "192.168.1.15 - - [03/Jun/2024 16:24:12] \"OPTIONS /askQuery HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Rating': 1}\n",
      "\"What is HackerEarth?\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "192.168.1.15 - - [03/Jun/2024 16:24:16] \"POST /askQuery HTTP/1.1\" 200 -\n",
      "192.168.1.15 - - [03/Jun/2024 16:25:47] \"OPTIONS /websearch HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Rating': -1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "192.168.1.15 - - [03/Jun/2024 16:25:50] \"POST /websearch HTTP/1.1\" 200 -\n",
      "192.168.1.15 - - [03/Jun/2024 16:26:17] \"OPTIONS /askQuery HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Rating': 1}\n",
      "\"What is HackerEarth?\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "192.168.1.15 - - [03/Jun/2024 16:26:21] \"POST /askQuery HTTP/1.1\" 200 -\n",
      "192.168.1.15 - - [03/Jun/2024 16:27:29] \"OPTIONS /askQuery HTTP/1.1\" 200 -\n",
      "192.168.1.15 - - [03/Jun/2024 16:27:29] \"OPTIONS /askQuery HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE1\n",
      "DONE1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-06-03 16:27:35,217] ERROR in app: Exception on /askQuery [POST]\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/mac/anaconda3/lib/python3.11/site-packages/flask/app.py\", line 2525, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mac/anaconda3/lib/python3.11/site-packages/flask/app.py\", line 1822, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mac/anaconda3/lib/python3.11/site-packages/flask_cors/extension.py\", line 176, in wrapped_function\n",
      "    return cors_after_request(app.make_response(f(*args, **kwargs)))\n",
      "                                                ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mac/anaconda3/lib/python3.11/site-packages/flask/app.py\", line 1820, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mac/anaconda3/lib/python3.11/site-packages/flask/app.py\", line 1796, in dispatch_request\n",
      "    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/pd/qtz24m7907db4zd40wq0yv940000gn/T/ipykernel_712/300045174.py\", line 128, in askQuery\n",
      "    vector_db, docs, pages = extract_data(link)\n",
      "                             ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/pd/qtz24m7907db4zd40wq0yv940000gn/T/ipykernel_712/3248492033.py\", line 12, in extract_data\n",
      "    db,docs,pages=extract_text('./main.pdf')\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/pd/qtz24m7907db4zd40wq0yv940000gn/T/ipykernel_712/4146490283.py\", line 2, in extract_text\n",
      "    pages=pdf_to_text(pdf_path)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/pd/qtz24m7907db4zd40wq0yv940000gn/T/ipykernel_712/2577321615.py\", line 6, in pdf_to_text\n",
      "    img=Image.open('page.jpg')\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mac/anaconda3/lib/python3.11/site-packages/PIL/Image.py\", line 3339, in open\n",
      "    raise UnidentifiedImageError(msg)\n",
      "PIL.UnidentifiedImageError: cannot identify image file '/Users/mac/Desktop/langchain/page.jpg'\n",
      "192.168.1.15 - - [03/Jun/2024 16:27:35] \"POST /askQuery HTTP/1.1\" 500 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page1done\n",
      "page2done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "192.168.1.15 - - [03/Jun/2024 16:27:45] \"POST /askQuery HTTP/1.1\" 200 -\n",
      "192.168.1.15 - - [03/Jun/2024 16:27:53] \"OPTIONS /askQuery HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Rating': -1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "192.168.1.15 - - [03/Jun/2024 16:27:54] \"POST /askQuery HTTP/1.1\" 200 -\n",
      "192.168.1.15 - - [03/Jun/2024 16:27:59] \"OPTIONS /askQuery HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Rating': -1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "192.168.1.15 - - [03/Jun/2024 16:28:01] \"POST /askQuery HTTP/1.1\" 200 -\n",
      "192.168.1.15 - - [03/Jun/2024 16:28:08] \"OPTIONS /askQuery HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Rating': 1}\n",
      "\"What is a cell?\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "192.168.1.15 - - [03/Jun/2024 16:28:12] \"POST /askQuery HTTP/1.1\" 200 -\n",
      "192.168.1.15 - - [03/Jun/2024 16:28:23] \"OPTIONS /askQuery HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Rating': 1}\n",
      "\"What is HackerEarth?\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "192.168.1.15 - - [03/Jun/2024 16:28:30] \"POST /askQuery HTTP/1.1\" 200 -\n",
      "192.168.1.15 - - [03/Jun/2024 16:29:54] \"OPTIONS /askQuery HTTP/1.1\" 200 -\n",
      "192.168.1.15 - - [03/Jun/2024 16:29:54] \"OPTIONS /askQuery HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE1\n",
      "DONE1\n",
      "page1done\n",
      "page1done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-06-03 16:30:06,941] ERROR in app: Exception on /askQuery [POST]\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/mac/anaconda3/lib/python3.11/site-packages/flask/app.py\", line 2525, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mac/anaconda3/lib/python3.11/site-packages/flask/app.py\", line 1822, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mac/anaconda3/lib/python3.11/site-packages/flask_cors/extension.py\", line 176, in wrapped_function\n",
      "    return cors_after_request(app.make_response(f(*args, **kwargs)))\n",
      "                                                ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mac/anaconda3/lib/python3.11/site-packages/flask/app.py\", line 1820, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mac/anaconda3/lib/python3.11/site-packages/flask/app.py\", line 1796, in dispatch_request\n",
      "    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/pd/qtz24m7907db4zd40wq0yv940000gn/T/ipykernel_712/300045174.py\", line 129, in askQuery\n",
      "    vector_db=add_to_db(docs)\n",
      "              ^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/pd/qtz24m7907db4zd40wq0yv940000gn/T/ipykernel_712/1697659785.py\", line 3, in add_to_db\n",
      "    faiss_db = Chroma.from_documents(docs,OpenAIEmbeddings())\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mac/anaconda3/lib/python3.11/site-packages/langchain_community/vectorstores/chroma.py\", line 778, in from_documents\n",
      "    return cls.from_texts(\n",
      "           ^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mac/anaconda3/lib/python3.11/site-packages/langchain_community/vectorstores/chroma.py\", line 736, in from_texts\n",
      "    chroma_collection.add_texts(\n",
      "  File \"/Users/mac/anaconda3/lib/python3.11/site-packages/langchain_community/vectorstores/chroma.py\", line 324, in add_texts\n",
      "    self._collection.upsert(\n",
      "  File \"/Users/mac/anaconda3/lib/python3.11/site-packages/chromadb/api/models/Collection.py\", line 477, in upsert\n",
      "    ) = self._validate_embedding_set(\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mac/anaconda3/lib/python3.11/site-packages/chromadb/api/models/Collection.py\", line 545, in _validate_embedding_set\n",
      "    valid_ids = validate_ids(maybe_cast_one_to_many_ids(ids))\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mac/anaconda3/lib/python3.11/site-packages/chromadb/api/types.py\", line 228, in validate_ids\n",
      "    raise ValueError(f\"Expected IDs to be a non-empty list, got {ids}\")\n",
      "ValueError: Expected IDs to be a non-empty list, got []\n",
      "192.168.1.15 - - [03/Jun/2024 16:30:06] \"POST /askQuery HTTP/1.1\" 500 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page2done\n",
      "page2done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "192.168.1.15 - - [03/Jun/2024 16:30:09] \"POST /askQuery HTTP/1.1\" 200 -\n",
      "192.168.1.15 - - [03/Jun/2024 16:30:21] \"OPTIONS /askQuery HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Rating': -1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "192.168.1.15 - - [03/Jun/2024 16:30:22] \"POST /askQuery HTTP/1.1\" 200 -\n",
      "192.168.1.15 - - [03/Jun/2024 16:31:10] \"OPTIONS /askQuery HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Rating': 1}\n",
      "\"What is a cell?\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "192.168.1.15 - - [03/Jun/2024 16:31:13] \"POST /askQuery HTTP/1.1\" 200 -\n",
      "192.168.1.15 - - [03/Jun/2024 16:38:33] \"OPTIONS /websearch HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Rating': 1}\n",
      "called\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "I will search for 'What is a cell?' and write an answer based on the results.\n",
      "{'tool_name': 'tavily_search_results_json', 'parameters': {'query': 'What is a cell?'}}\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m[{'url': 'https://www.nature.com/scitable/topicpage/what-is-a-cell-14023083/', 'content': 'A cell is the basic unit of life, surrounded by a membrane that controls what enters and exits. Cells contain various molecules and organelles that perform different functions, such as energy production, genetic expression, and communication.'}, {'url': 'https://www.britannica.com/science/cell-biology', 'content': 'Organelles include mitochondria, which are responsible for the energy transactions necessary for cell survival; lysosomes, which digest unwanted materials within the cell; and the endoplasmic reticulum and the Golgi apparatus, which play important roles in the internal organization of the cell by synthesizing selected molecules and then processing, sorting, and directing them to their proper locations. The cytosol contains an organized framework of fibrous molecules that constitute the cytoskeleton, which gives a cell its shape, enables organelles to move within the cell, and provides a mechanism by which the cell itself can move. The smallest known cells are a group of tiny bacteria called mycoplasmas; some of these single-celled organisms are spheres as small as 0.2 μm in diameter (1μm = about 0.000039 inch), with a total mass of 10−14 gram—equal to that of 8,000,000,000 hydrogen atoms. Certain proteins in the cell membrane are involved with cell-to-cell communication and help the cell to respond to changes in its environment.\\n In 1839 German physiologist\\xa0Theodor Schwann\\xa0and German botanist\\xa0Matthias Schleiden\\xa0promulgated that cells are the “elementary particles of organisms” in both plants and animals and recognized that some organisms are unicellular and others multicellular.\\xa0'}, {'url': 'https://www.khanacademy.org/science/biology/structure-of-a-cell/introduction-to-cells/a/intro-to-cells', 'content': 'Learn what cells are, how they were discovered, and why they are the basic units of life. Explore the history of cell theory and the diversity of cell types and shapes.'}, {'url': 'https://en.wikipedia.org/wiki/Cell_(biology)', 'content': \"The cell is the basic structural and functional unit of all forms of life. Every cell consists of cytoplasm enclosed within a membrane; many cells contain organelles, each with a specific function. The term comes from the Latin word cellula meaning 'small room'.\"}, {'url': 'https://biologydictionary.net/cell/', 'content': \"A cell is the basic unit of life that performs all of life's functions. Learn about the two major types of cells, prokaryotes and eukaryotes, and their subcategories, characteristics, and examples.\"}]\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "192.168.1.15 - - [03/Jun/2024 16:38:50] \"POST /websearch HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mRelevant Documents: 0,1,2,3,4\n",
      "Cited Documents: 0,1,2,3,4\n",
      "Answer: A cell is the basic unit of life, surrounded by a membrane that controls what enters and exits. Cells contain various molecules and organelles that perform different functions, such as energy production, genetic expression, and communication. The term 'cell' comes from the Latin word 'cellula', meaning 'small room'.\n",
      "Grounded answer: A cell is the <co: 0,2,3,4>basic unit of life</co: 0,2,3,4>, <co: 0,3>surrounded by a membrane</co: 0,3> that <co: 0>controls what enters and exits</co: 0>. Cells contain <co: 0,1>various molecules and</co: 0,1> <co: 0,1,3>organelles</co: 0,1,3> that <co: 0,1,3>perform different functions</co: 0,1,3>, such as <co: 0,1>energy production</co: 0,1>, <co: 0>genetic expression</co: 0>, and <co: 0,1>communication</co: 0,1>. The term 'cell' comes from the <co: 3>Latin word 'cellula</co: 3>', meaning <co: 3>'small room</co: 3>'.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "192.168.1.15 - - [03/Jun/2024 16:39:10] \"OPTIONS /askQuery HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Rating': -1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "192.168.1.15 - - [03/Jun/2024 16:39:12] \"POST /askQuery HTTP/1.1\" 200 -\n",
      "192.168.1.15 - - [03/Jun/2024 16:39:25] \"OPTIONS /askQuery HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Rating': 1}\n",
      "\"What is HackerEarth?\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "192.168.1.15 - - [03/Jun/2024 16:39:29] \"POST /askQuery HTTP/1.1\" 200 -\n",
      "192.168.1.15 - - [03/Jun/2024 16:39:40] \"OPTIONS /websearch HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Rating': 1}\n",
      "called\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "I will search for 'What is HackerEarth?' and write an answer based on the results.\n",
      "{'tool_name': 'tavily_search_results_json', 'parameters': {'query': 'What is HackerEarth?'}}\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m[{'url': 'https://en.wikipedia.org/wiki/HackerEarth', 'content': 'HackerEarth is a software company headquartered in San Francisco that provides enterprise software that assists organizations with technical hiring. HackerEarth is used by organizations for technical skill assessments and remote video interviewing .'}, {'url': 'https://www.linkedin.com/company/hackerearth', 'content': 'HackerEarth is the most comprehensive developer assessment software that helps companies to accurately measure the skills of developers during the recruiting process.'}, {'url': 'https://www.hackerearth.com/recruit/assessments/', 'content': 'HackerEarth allows you to customize the difficulty level of your coding assessments in several ways. You can choose from a library of pre-built questions with varying difficulty levels, or create your own custom questions with specific difficulty parameters. Additionally, you can set the time limit for each assessment to further tailor the ...'}, {'url': 'https://www.hackerearth.com/', 'content': 'HackerEarth is built for engineering teams, by an engineering team that hates a broken tech process and the inherent biases. Request a demo. Helping 10M+ developers be better through coding contests, data science competitions, and hackathons. Trusted by recruiters from 1,000+ companies hiring the best developers.'}, {'url': 'https://help.hackerearth.com/hc/en-us/articles/360003266273-Overview', 'content': 'Overview. HackerEarth is an online technical-recruitment tool that enables you to automate your hiring process to select the best fit for your team. Using HackerEarth Assessment, you can create tests to evaluate candidates. By automating your recruitment process, HackerEarth Assessment saves the time and effort required to go through hundreds ...'}]\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "192.168.1.15 - - [03/Jun/2024 16:39:53] \"POST /websearch HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mRelevant Documents: 0,1,2,3,4\n",
      "Cited Documents: 0,1,2,3,4\n",
      "Answer: HackerEarth is a software company that provides enterprise software to help organisations with technical hiring. It is used by engineering teams to automate their hiring process and select the best fit for their team. HackerEarth allows users to customise the difficulty level of their coding assessments, choose from a library of pre-built questions with varying difficulty levels, or create their own custom questions.\n",
      "Grounded answer: HackerEarth is a <co: 0>software company</co: 0> that provides <co: 0>enterprise software</co: 0> to help <co: 0,1,4>organisations with technical hiring</co: 0,1,4>. It is <co: 3>used by engineering teams</co: 3> to <co: 4>automate their hiring process</co: 4> and <co: 4>select the best fit for their team</co: 4>. HackerEarth allows users to <co: 2>customise the difficulty level of their coding assessments</co: 2>, <co: 2>choose from a library of pre-built questions with varying difficulty levels</co: 2>, or <co: 2>create their own custom questions</co: 2>.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from flask import Flask, request,send_from_directory\n",
    "from flask_cors import CORS\n",
    "token_user={}\n",
    "app = Flask(__name__)\n",
    "CORS(app)\n",
    "Multi_quiz_questions=None\n",
    "# Routes for single player quiz\n",
    "@app.route('/extractContent', methods=['POST'])\n",
    "def extractContent():\n",
    "    link = request.json.get('link')\n",
    "    global vector_db, docs, pages\n",
    "    vector_db, docs, pages = extract_data(link)\n",
    "    return {\"status\": \"ok\"}\n",
    "\n",
    "@app.route('/startQuiz', methods=['POST'])\n",
    "def startQuiz():\n",
    "    global level, docs, quiz_pages\n",
    "    var = request.json.get('var')\n",
    "#     print(var)\n",
    "    if(var==True):\n",
    "        link = request.json.get('link')\n",
    "        level = request.json.get('level')\n",
    "        db,docs,quiz_pages=extract_data(link)\n",
    "        print(quiz_pages)\n",
    "        questions = start_quiz2(level, docs, quiz_pages,0)\n",
    "#         que = questions.replace('\\n', '')\n",
    "#         data_json = json.loads(que)\n",
    "        data_json=convert_json(questions,'mixtral')\n",
    "        return {\"questions\": data_json}\n",
    "    else:\n",
    "        level = request.json.get('level')\n",
    "        questions = start_quiz2(level, docs, quiz_pages,1)\n",
    "#         que = questions.replace('\\n', '')\n",
    "#         data_json = json.loads(que)\n",
    "        data_json=convert_json(questions,'mixtral')\n",
    "        return {\"questions\": data_json}\n",
    "\n",
    "# Routes for two player quiz\n",
    "@app.route('/generateToken', methods=['POST'])\n",
    "def generate_token():\n",
    "    global level\n",
    "#     level = request.json.get('level')\n",
    "    username = request.json.get('username')\n",
    "    token = gen_tok(username)\n",
    "    return {'token':token}\n",
    "\n",
    "@app.route('/start2player', methods=['POST'])\n",
    "def start2player():\n",
    "    global Multi_quiz_questions,token_user\n",
    "#     global level, docs\n",
    "    chstatus=request.json.get('chStatus')\n",
    "    var=request.json.get('status')\n",
    "    if(var==400 or var==404):\n",
    "        username = request.json.get('username')\n",
    "        if username in token_user.keys():\n",
    "            if token_user[username][2]=='YES':\n",
    "                return {\"status\":\"200\"}\n",
    "    if(chstatus):\n",
    "        link=request.json.get('link')\n",
    "        level=request.json.get('level')\n",
    "        username = request.json.get('username')\n",
    "        db,docs,pages=extract_data(link)\n",
    "        Multi_quiz_questions = start_quiz2(level, docs, pages,0)\n",
    "#         que = Multi_quiz_questions.replace('\\n', '')\n",
    "#         data_json = json.loads(que)\n",
    "#         above 2 for mixtral model\n",
    "        data_json=convert_json(Multi_quiz_questions,'mixtral')\n",
    "#         print(username)\n",
    "#         print(token_user)\n",
    "        global user1,user2,marks1,marks2\n",
    "        user1={}\n",
    "        user2={}\n",
    "        token_user[username][1] = 'YES'\n",
    "       \n",
    "        return {\"questions\":data_json}\n",
    "    return {\"status\": \"404\"}\n",
    "\n",
    "@app.route('/verifyToken', methods=['POST'])\n",
    "def verifyToken():\n",
    "    global Multi_quiz_questions\n",
    "    token = request.json.get('token')\n",
    "    print(token_user)\n",
    "    for user, data in token_user.items():\n",
    "        if data[0] == token:\n",
    "            (token_user[user])[2]='YES'\n",
    "            while((token_user[user])[1]=='NO'):\n",
    "                pass\n",
    "            data_json=convert_json(Multi_quiz_questions,'mixtral')\n",
    "            return {\"questions\":data_json,\"status\":\"200\"}\n",
    "    return {\"status\":\"404\"}\n",
    "@app.route('/user1submit', methods=['POST'])\n",
    "def user1submit():\n",
    "    global user1\n",
    "    user1['username']=request.json.get('username')\n",
    "    user1['marks']=request.json.get('marks')\n",
    "    user1['wrong']=request.json.get('wrong')\n",
    "    return {'winner':Identify_winner(),'marks':user2['marks'],'wrong':user2['wrong']}\n",
    "@app.route('/user2submit', methods=['POST'])\n",
    "def user2submit():\n",
    "    global user2\n",
    "    user2['username']=request.json.get('username')\n",
    "    user2['marks']=request.json.get('marks')\n",
    "    user2['wrong']=request.json.get('wrong')\n",
    "    return {'winner':Identify_winner(),'marks':user1['marks'],'wrong':user1['wrong']}\n",
    "# Routes for paragraph writing questions\n",
    "@app.route('/paraQuizques', methods=['POST'])\n",
    "def para_Quiz_ques():\n",
    "    global docs, para_que\n",
    "    level = request.json.get('level')\n",
    "    para_que = gen_ques(docs, level)\n",
    "    return {\"question\": para_que}\n",
    "\n",
    "@app.route('/paraQuizans', methods=['POST'])\n",
    "def para_Quiz_Ans():\n",
    "    global para_que\n",
    "    ans = request.json.get('answer')\n",
    "    feedback = check_ans(para_que, ans)\n",
    "    return {\"ans_status\": feedback}\n",
    "\n",
    "# Route for asking queries\n",
    "@app.route('/askQuery', methods=['POST'])\n",
    "def askQuery():\n",
    "    global vector_db\n",
    "    check = request.json.get('var')\n",
    "    if check == 0:\n",
    "        link = request.json.get('link')\n",
    "        vector_db, docs, pages = extract_data(link)\n",
    "        vector_db=add_to_db(docs)\n",
    "        return {\"status\": \"ok\"}\n",
    "    else:\n",
    "        query = request.json.get('query')\n",
    "#         print(vector_db)\n",
    "        answer = query_check(query,vector_db,'local','Technical')\n",
    "        return {\"answer\":answer}\n",
    "@app.route('/websearch', methods=['POST'])\n",
    "def webSearch():\n",
    "    query=request.json.get('query')\n",
    "#     print(query)\n",
    "    ans=query_check(query,vector_db,'web','Technical')\n",
    "#     ans=web_Search(query)\n",
    "    return {'answer':ans}\n",
    "#     return {'ans':'hello'}\n",
    "####SSB IMAGE TEST ########\n",
    "@app.route('/ssbimage', methods=['POST'])\n",
    "def ssbimage():\n",
    "    global image_desc\n",
    "    image_desc=SSB_Image_generator(0)\n",
    "    return send_from_directory('./', 'main.png')\n",
    "@app.route('/qualitycheck', methods=['POST'])  \n",
    "def qualityCheck():\n",
    "    user_story = request.json.get('story')\n",
    "    return {\"description\":SSB_TEST_STORY(image_desc,user_story)}\n",
    "####Para question answering####\n",
    "@app.route('/paraque', methods=['POST']) \n",
    "def paraque():\n",
    "    global para_pages\n",
    "    para_questions=[]\n",
    "    link = request.json.get('link')\n",
    "    vector_db, docs, para_pages = extract_data(link)\n",
    "    que=gen_ques(para_pages,level,para_questions)\n",
    "#     print(que)\n",
    "    return {'questions':que}\n",
    "@app.route('/paraanswer', methods=['POST']) \n",
    "def paraAnswer():\n",
    "    global para_pages\n",
    "    user_ans=(request.json)['dummy']\n",
    "    print(user_ans)\n",
    "    result=check_ans(para_pages,user_ans)\n",
    "    print(result)\n",
    "    return {'result':result}\n",
    "#     return {\"status\":200}\n",
    "@app.route('/placement_que', methods=['POST']) \n",
    "def placement_que():\n",
    "    topic=gen_placement_que()\n",
    "    return {'question':topic}\n",
    "@app.route('/placement_res', methods=['POST']) \n",
    "def placement_res():\n",
    "    topic=request.json.get('question')\n",
    "    essay=request.json.get('answer')\n",
    "    res=check_placement_ans(topic,essay)\n",
    "    return {'result':res}\n",
    "if __name__ == '__main__':\n",
    "    app.run(host=\"0.0.0.0\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748b7929",
   "metadata": {},
   "source": [
    "# Download Pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bda3e50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "def extract_data(link):\n",
    "    global para_que\n",
    "    drive_link = link\n",
    "    file_id = drive_link.split(\"/\")[-2]\n",
    "    download_link = f\"https://drive.google.com/uc?id={file_id}\"\n",
    "    response = requests.get(download_link)\n",
    "    with open(\"main.pdf\", \"wb\") as file:\n",
    "        file.write(response.content)\n",
    "        \n",
    "    print('DONE1')\n",
    "    db,docs,pages=extract_text('./main.pdf')\n",
    "    return db,docs,pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "96730b31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE1\n",
      "page1done\n",
      "page2done\n",
      "page3done\n",
      "page4done\n",
      "page5done\n",
      "page6done\n",
      "page7done\n"
     ]
    }
   ],
   "source": [
    "db,docs,pages=extract_data('https://drive.google.com/file/d/19fD_lHWqUd89VV7epg83i1rTkTkOyVEv/view?usp=share_link')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e134c128",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The candidate's response lacks content and does not align with the image provided for the Picture Perception and Discussion Test (PPDT). The story is incomplete and does not reflect the details of the image depicting a group discussion on environmental conservation and climate change impact on Indian monsoons.\n",
      "\n",
      "Observation Skills: The candidate did not describe the key elements of the image, such as the diverse group of candidates, the setting of the SSB exam room, the discussion topic on environmental conservation, and the map of India with environmental markers.\n",
      "\n",
      "Imagination: The candidate's story is missing, and therefore, there is a lack of creativity or originality in creating a narrative based on the image.\n",
      "\n",
      "Writing Style: The response is extremely brief, with only the word \"hello\" provided. There are no grammar, vocabulary, or sentence structure to evaluate in this context.\n",
      "\n",
      "Officer Like Qualities (OLQs): The response does not demonstrate any leadership, initiative, effective communication, or positive attitude as required in the SSB evaluation.\n",
      "\n",
      "Overall, the candidate's performance is inadequate and does not meet the criteria for the Picture Perception and Discussion Test. The candidate needs to provide a detailed story based on the image provided to showcase their observational skills, imagination, writing style, and Officer Like Qualities.\n",
      "\n",
      "Rating: 1 out of 10"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The candidate\\'s response lacks content and does not align with the image provided for the Picture Perception and Discussion Test (PPDT). The story is incomplete and does not reflect the details of the image depicting a group discussion on environmental conservation and climate change impact on Indian monsoons.\\n\\nObservation Skills: The candidate did not describe the key elements of the image, such as the diverse group of candidates, the setting of the SSB exam room, the discussion topic on environmental conservation, and the map of India with environmental markers.\\n\\nImagination: The candidate\\'s story is missing, and therefore, there is a lack of creativity or originality in creating a narrative based on the image.\\n\\nWriting Style: The response is extremely brief, with only the word \"hello\" provided. There are no grammar, vocabulary, or sentence structure to evaluate in this context.\\n\\nOfficer Like Qualities (OLQs): The response does not demonstrate any leadership, initiative, effective communication, or positive attitude as required in the SSB evaluation.\\n\\nOverall, the candidate\\'s performance is inadequate and does not meet the criteria for the Picture Perception and Discussion Test. The candidate needs to provide a detailed story based on the image provided to showcase their observational skills, imagination, writing style, and Officer Like Qualities.\\n\\nRating: 1 out of 10'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SSB_TEST_STORY(image_desc,'hello')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd48e91b",
   "metadata": {},
   "source": [
    "# 2 Player Competetion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8c240a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "558da009",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_tok(username):\n",
    "    token=str(uuid.uuid1())[0:8]\n",
    "    token_user[username]=[token,'NO','NO']# 1st No=>1st player 2nd No for 2nd player\n",
    "    return token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f1992639",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Identify_winner():\n",
    "    while(user1=={} or user2=={}):\n",
    "        pass\n",
    "    if(user1['marks']>user2['marks']):\n",
    "        return user1['username']\n",
    "    else:\n",
    "        return user2['username']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd9e066",
   "metadata": {},
   "source": [
    "# Part 4 QA chatbot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "633ef4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "import os\n",
    "from langchain_community.vectorstores import Chroma,FAISS\n",
    "import json\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "import time\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_cohere import CohereRerank\n",
    "from langchain.retrievers.contextual_compression import ContextualCompressionRetriever\n",
    "from langchain.agents import AgentExecutor\n",
    "from langchain_cohere.chat_models import ChatCohere\n",
    "from langchain_cohere.react_multi_hop.agent import create_cohere_react_agent\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f0112935",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['GROQ_API_KEY']='GRQO_API_KEY_HERE'\n",
    "open_ai_key=\"OPEN_AI_API_KEY_HERE\"\n",
    "os.environ[\"OPENAI_API_KEY\"] = open_ai_key\n",
    "os.environ['COHERE_API_KEY']='COHERE_API_KEY_HERE'\n",
    "os.environ['TAVILY_API_KEY']='TAVILY_API_KEY_HRE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "738c9b30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mac/anaconda3/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.llms.openai.OpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "standalone_question_llm=ChatGroq(temperature=0.0, model_name=\"mixtral-8x7b-32768\",api_key='GROQ_API_KEY_HERE')\n",
    "answering_llm=ChatGroq(temperature=0.6, model_name=\"mixtral-8x7b-32768\",api_key='GROQ_API_KEY_HERE')\n",
    "compressor = CohereRerank(top_n=4)\n",
    "query_check_llm=OpenAI(temperature=0.5)\n",
    "greet_llm=ChatGroq(temperature=0.6, model_name=\"mixtral-8x7b-32768\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "1a4868a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "template1 = \"\"\"\n",
    "[INST] \n",
    "Given the following conversation and a follow up question, \n",
    "rephrase the follow up question to be a standalone question, in its original language, \n",
    "that can be used to query a FAISS index. This query will be used to retrieve documents with additional context.\n",
    "\n",
    "Let me share a couple examples.\n",
    "If you do not see any chat history, you MUST return the \"Follow Up Input\" as is:\n",
    "```\n",
    "Chat History:\n",
    "Follow Up Input: How is Lawrence doing?\n",
    "Standalone Question:\n",
    "How is Lawrence doing?\n",
    "```\n",
    "\n",
    "If this is the second question onwards, you should properly rephrase the question like this:\n",
    "```\n",
    "Chat History:\n",
    "Human: How is Lawrence doing?\n",
    "AI: \n",
    "Lawrence is injured and out for the season.\n",
    "Follow Up Input: What was his injury?\n",
    "Standalone Question:\n",
    "What was Lawrence's injury?\n",
    "```\n",
    "\n",
    "Now, with those examples, here is the actual chat history and input question.\n",
    "Chat History:\n",
    "{chat_history}\n",
    "Follow Up Input: {question}\n",
    "Standalone question:\n",
    "[your response here]\n",
    "[/INST] \n",
    "\"\"\"\n",
    "prompt2 = ChatPromptTemplate.from_template(\"\"\"\n",
    "Answer the following question based only on the provided context.\n",
    "<context>{context}</context>\n",
    "Think step by step before providing a detailed answer. \n",
    "I will tip you $1000 if the user finds the answer helpful. \n",
    "\n",
    "Question: {input}\n",
    "Kindly write the output in a Technical way\"\"\")\n",
    "query_check_template = '''\n",
    "Please analyze the following text and provide a rating for the level of inappropriate content.\n",
    "Rate it on a scale of 1 to 5, where 1 indicates no inappropriate content and 5\n",
    "indicates highly inappropriate content. Only provide the rating, no need to explain why:\n",
    "\n",
    "Text: {query}\n",
    "\n",
    "If you find the text as a greeting statement like \"Good morning\", \"Good evening\", \"Hi\", \"Hello\",\n",
    "\"How are you\", \"Bye\", \"Goodbye\", or anything you think is similar, rate them as -1.\n",
    "give results as:\n",
    "Rating:rate\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "7abec14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt1 = PromptTemplate(input_variables=[\"chat_history\", \"question\"], template=template1)\n",
    "QA_memory = ConversationBufferMemory(memory_key=\"chat_history\", input_key=\"question\")\n",
    "chain=prompt1|standalone_question_llm\n",
    "#----------------------------------------------------------------------------------------------------------\n",
    "query_check_prompt=PromptTemplate(input_variables=['query'],template=query_check_template)\n",
    "query_check_chain=query_check_prompt|query_check_llm\n",
    "#----------------------------------------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "5f5e0d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_check(query,faiss_db,search,way='Technical'):\n",
    "    rating=query_check_chain.invoke({\"query\":query})\n",
    "    key, value = rating.split(': ')\n",
    "    result_dict = {key.strip(): int(value)}\n",
    "    print(result_dict)\n",
    "    if(result_dict['Rating']==-1):\n",
    "        greet_template='''System Message:You are a helpful assistant. Greet people Politely\n",
    "        user Text:{query}'''\n",
    "        greet_prompt = PromptTemplate(input_variables=['query'],template=greet_template)\n",
    "        greet_chain = greet_prompt| greet_llm\n",
    "        ans=greet_chain.invoke({\"query\":query})\n",
    "        return ans.content\n",
    "    elif(result_dict['Rating']<4):\n",
    "        if(search=='local'):\n",
    "            ans=ans_query(query,faiss_db,way)\n",
    "        elif (search=='web'):\n",
    "            ans=web_Search(query)\n",
    "        return ans\n",
    "    else:\n",
    "        return \"Inappropriate Query\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "c9d24370",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ans_query(query,faiss_db,way='Technical'):\n",
    "        global QA_memory\n",
    "        main_question=chain.invoke({\"question\":query,\"chat_history\":QA_memory}).content\n",
    "        QA_memory.save_context({'question':query},{'answer':main_question})\n",
    "        print(main_question)\n",
    "        retriever=faiss_db.as_retriever() \n",
    "        compression_retriever = ContextualCompressionRetriever(\n",
    "        base_compressor=compressor, \n",
    "        base_retriever=retriever\n",
    "        )\n",
    "        document_chain=create_stuff_documents_chain(answering_llm,prompt2)\n",
    "        retrieval_chain=create_retrieval_chain(compression_retriever,document_chain)\n",
    "        ans=retrieval_chain.invoke({'input':main_question})\n",
    "        return ans['answer']\n",
    "#         model=OpenAI(temperature=0.5)\n",
    "#         chain2=prompt2|model|output_parser\n",
    "#         res=chain2.invoke({'input':main_question})\n",
    "#         return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ffc75926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"What is the code for JP Morgan Chase?\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Based on the provided context, the question seems to be misinterpreted as it is not related to programming code, but rather might be asking for a code or identifier for JP Morgan Chase.\\n\\nJP Morgan Chase does not have a single code, but they have different codes, identifiers, and abbreviations depending on the context. Some of them include:\\n\\n1. JPM (New York Stock Exchange Ticker Symbol): JPM is the ticker symbol for JP Morgan Chase on the New York Stock Exchange (NYSE).\\n\\n2. JPMorgan Chase Bank, N.A.: JPMorgan Chase Bank, N.A. is the legal name of the banking entity, and it can be used as a code or identifier for JP Morgan Chase in various situations.\\n\\n3. SWIFT/BIC Code: The SWIFT/BIC code for JPMorgan Chase Bank, N.A. varies depending on the location, but an example is CHASUS33.\\n\\n4. Routing Transit Number (RTN) or ABA Number: JPMorgan Chase Bank, N.A. uses different routing transit numbers (RTNs) or ABA numbers depending on the location and the type of transaction.\\n\\n5. LEI (Legal Entity Identifier): JPMorgan Chase & Co. has a Legal Entity Identifier (LEI) which is a unique identifier for legal entities involved in financial transactions: 5493007KCJPKCEVMOV80.\\n\\nThese codes and identifiers are used in various contexts, such as stock trading, international wire transfers, and regulatory reporting.'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query='what is jp morgan code chase'\n",
    "ans_query(query,db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "561918e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def web_Search(query):\n",
    "    print('called')\n",
    "    main_question=chain.invoke({\"question\":query,\"chat_history\":QA_memory}).content\n",
    "    internet_search = TavilySearchResults()\n",
    "    llm = ChatCohere()\n",
    "    agent = create_cohere_react_agent(\n",
    "        llm=llm,\n",
    "        tools=[internet_search],\n",
    "        prompt=ChatPromptTemplate.from_template(\"\"\"Answer the following question using the Web Tools \n",
    "    Think step by step before providing a detailed answer. \n",
    "    I will tip you $1000 if the user finds the answer helpful.\n",
    "    <question>\n",
    "    {question}\n",
    "    </question>\n",
    "    Answer the Question in around 1 paragraph.\n",
    "    \"\"\"),\n",
    "    )\n",
    "    agent_executor = AgentExecutor(agent=agent, tools=[internet_search], verbose=True)\n",
    "\n",
    "    response = agent_executor.invoke({\n",
    "    \"question\":main_question,\n",
    "    })\n",
    "    try:\n",
    "        ans=response.get('output')+'\\n'+(response.get(\"citations\")[0]).documents[0]['url']+'\\n'+(response.get(\"citations\")[1]).documents[0]['url']\n",
    "    except:\n",
    "         ans=response.get('output')\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b8bfa4",
   "metadata": {},
   "source": [
    "# SSB IMAGE TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "31ef61d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "import warnings\n",
    "from IPython.display import display\n",
    "from PIL import Image\n",
    "from stability_sdk import client\n",
    "from stability_sdk.client import generation\n",
    "from langchain_core.prompts.prompt import PromptTemplate\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.llms import OpenAI\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    AIMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.callbacks.manager import CallbackManager\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "67ea5e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "stability_api = client.StabilityInference(\n",
    "    host='Stable diffusion host url',\n",
    "    key='stable diffusion api here',\n",
    "    verbose=False,\n",
    ")\n",
    "open_ai_key=\"OPEN_AI_API_KEY\"\n",
    "os.environ[\"OPENAI_API_KEY\"] = open_ai_key\n",
    "os.environ['GROQ_API_KEY']='GROQ_API_KEY_HERE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1f31c4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_llm1 = OpenAI(temperature=0.7)\n",
    "desc_llm2=ChatGroq(temperature=0.7, model_name=\"mixtral-8x7b-32768\")\n",
    "evalutor_llm1 = ChatOpenAI(streaming=True, callback_manager=CallbackManager([StreamingStdOutCallbackHandler()]), verbose=True, temperature=0.6)\n",
    "evalutor_llm2= ChatGroq(temperature=0.6, model_name=\"mixtral-8x7b-32768\",streaming=True, callback_manager=CallbackManager([StreamingStdOutCallbackHandler()]), verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "312261ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "converstion=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2001b131",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SSB_Image_generator(memory):\n",
    "    global conversation\n",
    "    template='''SYSTEM:write me a prompt that can be given to model for generating images for Indian SSB exam. \n",
    "    Model should give me a detailed description about the image like:- how persons are sitting, \n",
    "    what topic they are discussing other elements like enviroment,animals, anything that can be used to check \n",
    "    a candidates imagination and leader ship qualities about there means a unique description of image \n",
    "    but one thing the model develops output containing 1st line as Create a black and white image .\n",
    "    Current conversation:\n",
    "    {history}\n",
    "    Human: {input}\n",
    "    AI Assistant:\n",
    "    '''\n",
    "    PROMPT = PromptTemplate(input_variables=[\"history\",'input'], template=template)\n",
    "    if(not memory):\n",
    "        conversation = ConversationChain(\n",
    "        prompt=PROMPT,\n",
    "        llm=desc_llm2,\n",
    "        verbose=False,\n",
    "        memory=ConversationBufferMemory(),\n",
    "        )\n",
    "        print(\"memory Initialized\")\n",
    "    description=conversation.predict(input='Write a unique description for me')\n",
    "    answers = stability_api.generate(\n",
    "    prompt=description,\n",
    "    )\n",
    "    print(\"generating image\")\n",
    "    for resp in answers:\n",
    "        for artifact in resp.artifacts:\n",
    "            if artifact.finish_reason == generation.FILTER:\n",
    "                warnings.warn(\n",
    "                    \"Your request activated the API's safety filters and could not be processed.\"\n",
    "                    \"Please modify the prompt and try again.\")\n",
    "            if artifact.type == generation.ARTIFACT_IMAGE:\n",
    "                img = Image.open(io.BytesIO(artifact.binary))\n",
    "                img.save('main.png')\n",
    "    #             display(img)\n",
    "    image_desc=description[25:]\n",
    "    return image_desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "cff7c3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SSB_TEST_STORY(image_desc,story):\n",
    "    prompt=PromptTemplate(\n",
    "    template='''\n",
    "            You are an evaluator at the Services Selection Board (SSB), tasked with evaluating a candidate's response to the Picture Perception and Discussion Test (PPDT). The candidate has provided a brief description of the image and a story based on it. Your task is to evaluate the candidate's performance based on the following criteria:\n",
    "\n",
    "    Observation Skills: Consider how well the candidate has described the features of the image. Did they capture the key details accurately?\n",
    "    Imagination: Evaluate the creativity and originality of the candidate's story. Did they demonstrate the ability to create a compelling narrative based on the image?\n",
    "    Writing Style: Assess the candidate's writing style, including grammar, vocabulary, and sentence structure. Did they communicate their ideas effectively?\n",
    "    Officer Like Qualities (OLQs): Look for qualities such as leadership, initiative, effective communication, and positive attitude in the candidate's response.\n",
    "    Provide specific feedback on the candidate's performance, highlighting any grammatical errors, vocabulary usage, or areas for improvement. Finally, rate the candidate's overall performance on a scale of 1 to 10, with 10 being the highest.\n",
    "\n",
    "    Description of the Image:\n",
    "    {image_desc}\n",
    "\n",
    "    will Provide you Candidate's Story''',\n",
    "    input_variables=[\"image_desc\"]\n",
    "    )\n",
    "\n",
    "    system_message_prompt = SystemMessagePromptTemplate(prompt=prompt)\n",
    "    human_template='''\n",
    "    <user-story>\n",
    "    {story}\n",
    "    </user-story>\n",
    "    '''\n",
    "    human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
    "    chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])\n",
    "    chat_prompt_with_values = chat_prompt.format_prompt(image_desc=image_desc,story=story)\n",
    "    ans=evalutor_llm1(chat_prompt_with_values.to_messages())\n",
    "    ans=(ans.content).replace('\\n','<br></br>')\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ea865b",
   "metadata": {},
   "source": [
    "# PLACEMENT TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5927d4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "placement_ques_model=ChatGroq(temperature=0.6,model_name=\"mixtral-8x7b-32768\")\n",
    "placement_ans_model=OpenAI(temperature=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "76fa3674",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_placement_que():\n",
    "    prompt=PromptTemplate(\n",
    "    template='''provide an essay topic that are currently hot \n",
    "    and relevant in the tech industry, particularly focusing on themes\n",
    "    and questions asked by {comp} companies (Facebook, Amazon, Apple, Netflix, Google). T\n",
    "    he topics should be suitable for evaluating candidates' knowledge, critical thinking, and \n",
    "    communication skills. Each topic should be clearly stated and designed to be answered in a\n",
    "    pproximately 200 words.\n",
    "    <Example Topics>\n",
    "    The Ethical Implications of Artificial Intelligence in Social Media Platforms.\n",
    "    The Role of Cloud Computing in Modern Business.\n",
    "    The Future of Remote Work and Its Impact on the Tech Industry.\n",
    "    Data Privacy and User Security in Digital Services.\n",
    "    </Example Topics>''',\n",
    "        input_variables=['comp']\n",
    "    )\n",
    "    placement_chain=prompt|placement_ques_model|output_parser\n",
    "    topic=placement_chain.invoke({'comp':'FAANG'})\n",
    "    ind=topic.index('\\n')\n",
    "    topic=(topic[0:ind])+'''<br></br> Write a 200 words essay on the given topic.<br></br>\n",
    "    Basis of Evaluation:coherence, relevance to the topic, structure, grammar, vocabulary, and originality of ideas.'''\n",
    "#     topic=topic.replace('\\n','<br></br>')\n",
    "    return topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f647d1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "que=gen_placement_que()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "bae10201",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"The Impact of Deepfakes on Society and Their Implications for Online Platforms\"<br></br> Write a 200 words essay on the given topic.<br></br>\\n    Basis of Evaluation:coherence, relevance to the topic, structure, grammar, vocabulary, and originality of ideas.'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "que"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "76c8a254",
   "metadata": {},
   "outputs": [],
   "source": [
    "ans='''Artificial Intelligence (AI) and Machine Learning (ML) have significantly transformed \n",
    "customer experience across various industries. Discuss how AI and ML technologies are being \n",
    "utilized to improve customer interactions, personalize services, and predict customer needs. \n",
    "Additionally, analyze the potential challenges and ethical considerations that companies should \n",
    "address when implementing these technologies. Provide specific examples to support your arguments, \n",
    "and suggest ways in which businesses can balance innovation with customer trust and data privacy.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2b2f59b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_placement_ans(que,ans):\n",
    "    prompt=PromptTemplate(\n",
    "    template='''\n",
    "    You are provided with an essay written by a candidate in \n",
    "    response to a given topic:\n",
    "    <topic>\n",
    "    {topic}\n",
    "    </topic>\n",
    "    Evaluate the essay based on the following criteria: \n",
    "    coherence, relevance to the topic, structure, grammar, vocabulary, and originality of ideas.\n",
    "    Provide a detailed evaluation report including scores (out of 10) for each criterion and \n",
    "    constructive feedback for improvement.\n",
    "\n",
    "    <Candidate's Essay>\n",
    "    {essay}\n",
    "    </Candidate's Essay>\n",
    "    ''',input_variables=['essay','topic'])\n",
    "    placement_chain=prompt|placement_ans_model|output_parser\n",
    "    res=placement_chain.invoke({'topic':que,'essay':ans})\n",
    "    res=res.replace('\\n','<br></br>')\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "bdbb3ed1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<br></br>Coherence:<br></br>Score: 9/10<br></br>Constructive Feedback: The essay is well-structured and flows smoothly from one idea to the next. However, there are a few instances where the transition between paragraphs could be improved for better coherence.<br></br><br></br>Relevance to the topic:<br></br>Score: 10/10<br></br>Constructive Feedback: The essay is highly relevant to the given topic and effectively addresses all the key questions provided. The candidate has demonstrated a strong understanding of the role of AI and ML in enhancing customer experience.<br></br><br></br>Structure:<br></br>Score: 9/10<br></br>Constructive Feedback: The essay has a clear and logical structure, with an introduction, body, and conclusion. However, the introduction could be improved by providing a brief overview of what the essay will cover.<br></br><br></br>Grammar:<br></br>Score: 8/10<br></br>Constructive Feedback: The essay has a few minor grammatical errors, such as missing articles and incorrect verb tenses. Proofreading the essay before submission would help eliminate these errors.<br></br><br></br>Vocabulary:<br></br>Score: 9/10<br></br>Constructive Feedback: The candidate has used a wide range of vocabulary and has effectively explained technical terms. However, there is room for improvement in using more precise and concise language in some areas.<br></br><br></br>Originality of ideas:<br></br>Score: 10'"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_placement_ans(que,ans)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
